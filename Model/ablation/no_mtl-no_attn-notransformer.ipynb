{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b3655f4-7a07-455e-8b67-246673d94d83",
   "metadata": {},
   "source": [
    "Remove MTL in downstream, i.e. STL with patient data.\n",
    "\n",
    "Remove attention in pretraining, and remove transformer inputs, use `ablation_noattn_notransformer` folder for pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8435a94-3245-49ab-b4e9-3cd8f1562bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6482d30-3ef6-4263-baa0-779f7c93c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import yaml\n",
    "import pprint\n",
    "import os\n",
    "import wandb\n",
    "import sys\n",
    "import random\n",
    "from scipy.stats import mode, pearsonr\n",
    "import pickle\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.gaussian_multinomial_diffusion import GaussianMultinomialDiffusion\n",
    "from src.modules import MLPDiffusion\n",
    "from src.vae_model import vae\n",
    "from src.loss_functions import get_kld_loss, coral\n",
    "from model_definition import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d4470-75ea-4b9a-b014-0b99e1b94a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f87a87-38a2-4807-8433-aeda1621fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "CONFIG_PATH = f\"../experiment_settings_yaml/ablation/model_config_2A_annotated_mutations_v7_fold{fold}_noattn_notransformer.yaml\" # model config path\n",
    "pretty_print = pprint.PrettyPrinter()\n",
    "print(f\"Loading config from {CONFIG_PATH}\")\n",
    "config = yaml.safe_load(open(CONFIG_PATH))\n",
    "model_config = config[\"model_hyperparams\"]\n",
    "folder_config = config[\"folder_config\"]\n",
    "wandb_config = config[\"wandb_config\"]\n",
    "wandb_config[\"project_name\"] = wandb_config[\"project_name\"] + f\"-{model_config['experiment_id']}-{model_config['experiment_settings']}-fold{model_config['sample_id']}\" # updates wandb project name for ease of monitoring and logging.\n",
    "device = torch.device(f\"cuda:{model_config['device']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "genes_324 = list(pd.read_csv(f\"{folder_config['data_folder']}/raw/metadata/gene2ind.txt\", header=None)[0])\n",
    "drug_fp = pd.read_csv(f\"{folder_config['data_folder']}/raw/metadata/drug_morgan_fingerprints.csv\", index_col=0)\n",
    "suffixes = [\"_piu_max\", \"_piu_sum\", \"_piu_mean\", \"_piu_count\",\n",
    "            \"_lu_max\", \"_lu_sum\", \"_lu_mean\", \"_lu_count\",\n",
    "            \"_ncu_max\", \"_ncu_sum\", \"_ncu_mean\", '_ncu_count',\n",
    "            \"_pathogenic_max\", \"_pathogenic_sum\", \"_pathogenic_mean\", \"_pathogenic_count\",\n",
    "            \"_vus_max\", \"_vus_sum\", \"_vus_mean\", \"_vus_count\",\n",
    "            \"_benign_max\", \"_benign_sum\", \"_benign_mean\", \"_benign_count\"\n",
    "           ]\n",
    "genes_7776 = []\n",
    "for s in suffixes:\n",
    "    for g in list(pd.read_csv(f\"{folder_config['data_folder']}/raw/metadata/gene2ind.txt\", header=None)[0]):\n",
    "        genes_7776.append(f\"{g}{s}\")\n",
    "\n",
    "# setting up wandb\n",
    "os.environ[\"WANDB_CACHE_DIR\"] = wandb_config[\"wandb_cache_dir\"]\n",
    "os.environ[\"WANDB_DIR\"] = wandb_config[\"wandb_cache_dir\"]\n",
    "wandb.login(key=wandb_config[\"api_key\"])\n",
    "\n",
    "# seeding\n",
    "torch.manual_seed(model_config[\"seed\"])\n",
    "random.seed(model_config[\"seed\"])\n",
    "np.random.seed(model_config[\"seed\"])\n",
    "# reproducibility in data loading - https://pytorch.org/docs/stable/notes/randomness.html\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(model_config[\"seed\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc87d5a-fc7b-4171-994d-5ef2d10cc1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_folder = \"/data/ajayago/papers_data/DiffDRP_v7/run_files/saved_model_annotated_mutations/ablation/ablation_noattn_notransformer/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0269e6-03fe-49c4-b22b-fe6da00c700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass samples through the VAE and DDPM network, till just before VAE decoder\n",
    "def vae_decoder_input(df, vae, diff_model):\n",
    "    \"\"\"\n",
    "    Takes input df, pretrained vae and diffusion model as inputs, runs forward pass till VAE decoder\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch = torch.tensor(df.values) # convert to torch tensor\n",
    "        inp_vae = batch.to(device, dtype=torch.float32)\n",
    "        inp, mu, logvar, _ = vae(inp_vae) # From VAE encoder + reparameterization\n",
    "        \n",
    "        noise = torch.randn_like(inp) # this is the label we use   \n",
    "        b = inp.shape[0]\n",
    "        t = (torch.ones((b,)) * 700).long().to(device) # fixing time steps to 700\n",
    "        pt = torch.ones_like(t).float() / diff_model.num_timesteps\n",
    "        inp_t = diff_model.gaussian_q_sample(inp, t, noise) # forward process with cell line model encoder\n",
    "        \n",
    "        model_out = diff_model._denoise_fn(inp_t, t) # predicted epsilon from patient decoder\n",
    "    \n",
    "        # predict inp from noise using patient model\n",
    "        inp_pred = diff_model._predict_xstart_from_eps(inp_t, t, model_out)\n",
    "\n",
    "    return inp_pred.detach().cpu().numpy()\n",
    "\n",
    "def load_pretrained_models():\n",
    "    pretrained = torch.load(f\"{pretrained_folder}/best_pretrained_validation_loss_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.pth\")\n",
    "    is_real = True if model_config[\"input_data_type\"] == \"binary_mutations\" else False\n",
    "    # patients\n",
    "    patient_vae = vae(input_dim=model_config[\"feature_num\"], k_list=model_config[\"patient_vae_k_list\"], actf_list=model_config[\"patient_vae_actf_list\"], is_real=is_real).to(device)\n",
    "    tcga_mlp_diffusion_model = MLPDiffusion(d_in=model_config[\"patient_vae_k_list\"][-1]//2, num_classes=0, is_y_cond=False, rtdl_params={\"d_layers\": [model_config[\"patient_vae_k_list\"][-1]//4], \"dropout\": model_config[\"dropout\"]}).to(device)\n",
    "    tcga_diff_model = GaussianMultinomialDiffusion(num_classes=np.array([0]), num_numerical_features=model_config[\"patient_vae_k_list\"][-1]//2, denoise_fn=tcga_mlp_diffusion_model, device=device)#.to(device)\n",
    "    tcga_diff_model.load_state_dict(pretrained[\"patient_diff_model\"])\n",
    "    patient_vae.load_state_dict(pretrained[\"patient_vae_conditioned\"])\n",
    "    # cell lines\n",
    "    cl_vae = vae(input_dim=model_config[\"feature_num\"], k_list=model_config[\"cl_vae_k_list\"], actf_list=model_config[\"cl_vae_actf_list\"], is_real=is_real).to(device)\n",
    "    cl_mlp_diffusion_model = MLPDiffusion(d_in=model_config[\"cl_vae_k_list\"][-1]//2, num_classes=0, is_y_cond=False, rtdl_params={\"d_layers\": [model_config[\"cl_vae_k_list\"][-1]//4], \"dropout\": model_config[\"dropout\"]}).to(device)\n",
    "    cl_diff_model = GaussianMultinomialDiffusion(num_classes=np.array([0]), num_numerical_features=model_config[\"cl_vae_k_list\"][-1]//2, denoise_fn=cl_mlp_diffusion_model, device=device)#.to(device)\n",
    "    cl_diff_model.load_state_dict(pretrained[\"cl_diff_model\"])\n",
    "    cl_vae.load_state_dict(pretrained[\"cl_vae_conditioned\"])\n",
    "    return cl_diff_model, cl_vae, tcga_diff_model, patient_vae\n",
    "\n",
    "def load_datasets(sample_id):\n",
    "    \"\"\"\n",
    "    Takes sample_id as input, loads source and target train, validation and test splits (predefined files from Processing folder).\n",
    "    \"\"\"\n",
    "    data_dir = folder_config[\"data_folder\"] + \"input_types/\"\n",
    "    # navigate based on input type\n",
    "    if model_config[\"input_data_type\"] == \"binary_mutations\":\n",
    "        data_dir = data_dir + \"raw_mutations/\"\n",
    "        features2select = genes_324  # inclusive of Morgan drug fingerprints of 2048 dim\n",
    "    elif model_config[\"input_data_type\"] == \"annotated_mutations\":\n",
    "        data_dir = data_dir + \"annotated_mutations/\"\n",
    "        features2select = genes_7776  # inclusive of Morgan drug fingerprints of 2048 dim\n",
    "    elif model_config[\"input_data_type\"] == \"transformer_inputs\": # processed by PREDICT-AI transformer embedder\n",
    "        data_dir = data_dir + \"transformer_inputs_transformed_797/\"\n",
    "        features2select = [f\"transformer_embedded_{i}\" for i in range(797)] # after transformer embedding\n",
    "    else:\n",
    "        print(\"Unsupported input type!\")\n",
    "        return\n",
    "    \n",
    "    # navigate based on experiment id\n",
    "    if model_config[\"experiment_id\"] == \"1A\":\n",
    "        data_dir = data_dir + \"Experiment1/SettingA/\"\n",
    "    elif model_config[\"experiment_id\"] == \"1B\":\n",
    "        data_dir = data_dir + \"Experiment1/SettingB/\"\n",
    "    elif model_config[\"experiment_id\"] == \"2A\":\n",
    "        data_dir = data_dir + \"Experiment2/SettingA/\"\n",
    "    elif model_config[\"experiment_id\"] == \"2B\":\n",
    "        data_dir = data_dir + \"Experiment2/SettingB/\"\n",
    "    else:\n",
    "        print(\"Unsupported experiment ID!\")\n",
    "        return\n",
    "    \n",
    "    # load the fold based on sample_id - Note: cell lines have only 1 fold (fold 0)\n",
    "    with open(f\"{data_dir}/cell_lines_fold0_processed.pkl\", \"rb\") as f:\n",
    "        source_data = pickle.load(f)\n",
    "\n",
    "    with open(f\"{data_dir}/patients_fold{sample_id}_processed.pkl\", \"rb\") as f:\n",
    "        target_data = pickle.load(f)\n",
    "\n",
    "    # load pretrained TCGA VAE and diffusion models\n",
    "    # pass data points through patient DDPM and get the input to VAE decoder for DRP\n",
    "    cl_diff_model, cl_vae, tcga_diff_model, patient_vae = load_pretrained_models()\n",
    "    \n",
    "    # select data based on experiment settings \n",
    "    # Can be CISPLATIN, PACLITAXEL, FLUOROURACIL, SORAFENIB for 1A, CISPLATIN, TCGA-CESC; CISPLATIN, TCGA-HNSC; PACLITAXEL, TCGA-BRCA; FLUOROURACIL, TCGA-STAD for 1B\n",
    "    # ALL for 2A, TCGA-BRCA, TCGA-CESC, TCGA-HNSC, TCGA-STAD for 2B\n",
    "    if model_config[\"experiment_id\"] in [\"1A\", \"2B\"]:\n",
    "        setting = model_config[\"experiment_settings\"]\n",
    "        train_source_data, val_source_data, test_source_data = source_data[\"train\"][setting], source_data[\"val\"][setting], source_data[\"test\"][setting]\n",
    "        train_target_data, val_target_data, test_target_data = target_data[\"train\"][setting], target_data[\"val\"][setting], target_data[\"test\"][setting]\n",
    "    elif model_config[\"experiment_id\"] == \"1B\":\n",
    "        setting = (model_config[\"experiment_settings\"].split(\", \")[0], model_config[\"experiment_settings\"].split(\", \")[1], \"TCGA\")\n",
    "        train_source_data, val_source_data, test_source_data = source_data[\"train\"][setting], source_data[\"val\"][setting], source_data[\"test\"][setting]\n",
    "        train_target_data, val_target_data, test_target_data = target_data[\"train\"][setting], target_data[\"val\"][setting], target_data[\"test\"][setting]\n",
    "    elif model_config[\"experiment_id\"] == \"2A\":\n",
    "        train_source_data, val_source_data, test_source_data = source_data[\"train\"], source_data[\"val\"], source_data[\"test\"]\n",
    "        train_target_data, val_target_data, test_target_data = target_data[\"train\"], target_data[\"val\"], target_data[\"test\"]\n",
    "    else:\n",
    "        print(\"Unsupported experiment settings and ID\")\n",
    "        return\n",
    "    \n",
    "    # merge dataframes with drug Morgan fingprint dataframes\n",
    "    train_source_data_merged = train_source_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "    val_source_data_merged = val_source_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "    test_source_data_merged = test_source_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "\n",
    "    train_target_data_merged = train_target_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "    val_target_data_merged = val_target_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "    test_target_data_merged = test_target_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "\n",
    "    assert train_source_data_merged.shape[0] == train_source_data.shape[0], \"Train source data loss after merge!\"\n",
    "    assert val_source_data_merged.shape[0] == val_source_data.shape[0], \"Val source data loss after merge!\"\n",
    "    assert test_source_data_merged.shape[0] == test_source_data.shape[0], \"Test source data loss after merge!\"\n",
    "    assert train_target_data_merged.shape[0] == train_target_data.shape[0], \"Train target data loss after merge!\"\n",
    "    assert val_target_data_merged.shape[0] == val_target_data.shape[0], \"Val target data loss after merge!\"\n",
    "    assert test_target_data_merged.shape[0] == test_target_data.shape[0], \"Test target data loss after merge!\"\n",
    "\n",
    "    # separate out into input, drug and labels\n",
    "    train_source_inputs, val_source_inputs, test_source_inputs = train_source_data_merged[features2select], val_source_data_merged[features2select], test_source_data_merged[features2select]\n",
    "    # pass cl samples through cl diff model and vae\n",
    "    train_source_inputs_vae = pd.DataFrame(vae_decoder_input(train_source_inputs, cl_vae, cl_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"cl_vae_k_list\"][-1]//2)], index=train_source_data_merged.index)\n",
    "    val_source_inputs_vae = pd.DataFrame(vae_decoder_input(val_source_inputs, cl_vae, cl_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"cl_vae_k_list\"][-1]//2)], index=val_source_data_merged.index)\n",
    "    test_source_inputs_vae = pd.DataFrame(vae_decoder_input(test_source_inputs, cl_vae, cl_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"cl_vae_k_list\"][-1]//2)], index=test_source_data_merged.index)\n",
    "    train_source_drugs, val_source_drugs, test_source_drugs = train_source_data_merged[[str(i) for i in range(0, 2048)]].values, val_source_data_merged[[str(i) for i in range(0, 2048)]].values, test_source_data_merged[[str(i) for i in range(0, 2048)]].values\n",
    "    train_source_labels, val_source_labels, test_source_labels = train_source_data_merged[\"auc\"].values, val_source_data_merged[\"auc\"].values, test_source_data_merged[\"auc\"].values\n",
    "\n",
    "    train_target_inputs, val_target_inputs, test_target_inputs = train_target_data_merged[features2select], val_target_data_merged[features2select], test_target_data_merged[features2select]\n",
    "    # pass patient samples through tcga diff model and vae\n",
    "    train_target_inputs_vae = pd.DataFrame(vae_decoder_input(train_target_inputs, patient_vae, tcga_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"patient_vae_k_list\"][-1]//2)], index=train_target_data_merged.sample_id)\n",
    "    val_target_inputs_vae = pd.DataFrame(vae_decoder_input(val_target_inputs, patient_vae, tcga_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"patient_vae_k_list\"][-1]//2)], index=val_target_data_merged.sample_id)\n",
    "    test_target_inputs_vae = pd.DataFrame(vae_decoder_input(test_target_inputs, patient_vae, tcga_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"patient_vae_k_list\"][-1]//2)], index=test_target_data_merged.sample_id)\n",
    "\n",
    "    train_target_drugs, val_target_drugs, test_target_drugs = train_target_data_merged[[str(i) for i in range(0, 2048)]].values, val_target_data_merged[[str(i) for i in range(0, 2048)]].values, test_target_data_merged[[str(i) for i in range(0, 2048)]].values\n",
    "    train_target_labels, val_target_labels, test_target_labels = train_target_data_merged[\"recist\"].values, val_target_data_merged[\"recist\"].values, test_target_data_merged[\"recist\"].values\n",
    "\n",
    "    return train_source_inputs_vae, train_source_drugs, train_source_labels, val_source_inputs_vae, val_source_drugs, val_source_labels, test_source_inputs_vae, test_source_drugs, test_source_labels, train_target_inputs_vae, train_target_drugs, train_target_labels, val_target_inputs_vae, val_target_drugs, val_target_labels, test_target_inputs_vae, test_target_drugs, test_target_labels, train_target_data_merged, val_target_data_merged, test_target_data_merged, train_source_data_merged, val_source_data_merged, test_source_data_merged\n",
    "\n",
    "    # pass # needs to return (train_source_data, train_source_labels, val_source_data, val_source_labels, test_source_data, test_source_labels), (train_target_data, train_target_labels, val_target_data, val_target_labels, test_target_data, test_target_labels)\n",
    "    #  Dummy data\n",
    "    # train_source_data, val_source_data, test_source_data = np.random.rand(32, 2048 + 4), np.random.rand(10, 2048 + 4), np.random.rand(5, 2048 + 4)\n",
    "    # train_source_labels, val_source_labels, test_source_labels = np.random.randint(2, size=32), np.random.randint(2, size=10), np.random.randint(2, size=5)\n",
    "    # train_target_data, val_target_data, test_target_data = np.random.rand(32, 2048 + 4), np.random.rand(10, 2048 + 4), np.random.rand(3, 2048 + 4)\n",
    "    # train_target_labels, val_target_labels, test_target_labels = np.random.randint(2, size=32), np.random.randint(2, size=10), np.random.randint(2, size=3)\n",
    "    # return train_source_data, train_source_labels, val_source_data, val_source_labels, test_source_data, test_source_labels, train_target_data, train_target_labels, val_target_data, val_target_labels, test_target_data, test_target_labels\n",
    "\n",
    "def load_augmented_cl_dataset(sample_id):\n",
    "    augmented_cl_df = pd.read_csv(f\"{pretrained_folder}/augmented_cl_clconditioned_uda_v2_vaeinput_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.csv\", index_col=0)\n",
    "    print(f\"Loaded augmented CL data: {augmented_cl_df.shape}\")\n",
    "    return augmented_cl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db0bc9-b9eb-4cd1-adc7-ea92e0244aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_diff_model, cl_vae, tcga_diff_model, patient_vae = load_pretrained_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37ebec-6945-4f83-9c2d-ea08154ff733",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_inputs_vae, train_source_drugs, train_source_labels, val_source_inputs_vae, val_source_drugs, val_source_labels, test_source_inputs_vae, test_source_drugs, test_source_labels, train_target_inputs_vae, train_target_drugs, train_target_labels, val_target_inputs_vae, val_target_drugs, val_target_labels, test_target_inputs_vae, test_target_drugs, test_target_labels, train_target_data_merged, val_target_data_merged, test_target_data_merged, train_source_data_merged, val_source_data_merged, test_source_data_merged = load_datasets(sample_id=fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ff108-3007-49fc-9404-12b4cdbb03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2935b5a-e494-46c0-82a5-ff0a1cc7910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_data_merged[[\"sample_id\", \"drug_name\", \"auc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad38c3-1b28-416a-ab7f-94eb548683f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53300c9-3437-4cf7-9964-00c5afad4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_data_merged[genes_7776]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f699e022-32a2-47f7-95d7-0a5fd4da9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_data_merged[[\"sample_id\", \"drug_name\", \"recist\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3524e4-658f-4b3d-9c03-db60dad57819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "# Cell Lines\n",
    "source_dataset_train = TensorDataset(torch.FloatTensor(train_source_data_merged[genes_7776].values), torch.FloatTensor(train_source_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(train_source_data_merged[\"auc\"].values))\n",
    "source_dataset_val = TensorDataset(torch.FloatTensor(val_source_data_merged[genes_7776].values), torch.FloatTensor(val_source_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(val_source_data_merged[\"auc\"].values))\n",
    "source_dataset_test = TensorDataset(torch.FloatTensor(test_source_data_merged[genes_7776].values), torch.FloatTensor(test_source_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(test_source_data_merged[\"auc\"].values))\n",
    "\n",
    "# Patients\n",
    "target_dataset_train = TensorDataset(torch.FloatTensor(train_target_data_merged[genes_7776].values), torch.FloatTensor(train_target_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(train_target_data_merged[\"recist\"].values))\n",
    "target_dataset_val = TensorDataset(torch.FloatTensor(val_target_data_merged[genes_7776].values), torch.FloatTensor(val_target_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(val_target_data_merged[\"recist\"].values))\n",
    "target_dataset_test = TensorDataset(torch.FloatTensor(test_target_data_merged[genes_7776].values), torch.FloatTensor(test_target_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(test_target_data_merged[\"recist\"].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6116eae-ff0c-4bc0-a2a9-c6a4dfc79b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loaders\n",
    "source_dataloader_train = DataLoader(source_dataset_train, batch_size = 512, shuffle = True, worker_init_fn = seed_worker, generator = g)\n",
    "target_dataloader_train = DataLoader(target_dataset_train, batch_size = 512, shuffle = True, worker_init_fn = seed_worker, generator = g)\n",
    "\n",
    "source_dataloader_val = DataLoader(source_dataset_val, batch_size = 512, shuffle = False, worker_init_fn = seed_worker, generator = g)\n",
    "target_dataloader_val = DataLoader(target_dataset_val, batch_size = 512, shuffle = False, worker_init_fn = seed_worker, generator = g)\n",
    "\n",
    "source_dataloader_test = DataLoader(source_dataset_test, batch_size = 512, shuffle = False, worker_init_fn = seed_worker, generator = g)\n",
    "target_dataloader_test = DataLoader(target_dataset_test, batch_size = 512, shuffle = False, worker_init_fn = seed_worker, generator = g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67665274-c235-43e2-9840-631186c8c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STL(nn.Module):\n",
    "    def __init__(self, cl_vae, patient_vae):\n",
    "        super().__init__()\n",
    "        # self.cl_vae = cl_vae\n",
    "        self.patient_vae = patient_vae\n",
    "        self.drug_embedder = nn.Sequential(nn.Linear(2048, 256), nn.ReLU(), nn.Linear(256, 64))\n",
    "        # self.audrc_predictor = nn.Sequential(nn.Linear(64 * 2, 16), nn.ReLU(), nn.Linear(16, 1))\n",
    "        self.recist_predictor = nn.Sequential(nn.Linear(64 * 2, 16), nn.ReLU(), nn.Linear(16, 1))\n",
    "\n",
    "    def forward(self, cl_inp, cl_drug, patient_inp, patient_drug, audrc, recist):\n",
    "        # cl_inp and patient_inp are 797 dim, both drugs are 2048 dim\n",
    "        # cl_inp_emb, _, _, _ = self.cl_vae(cl_inp) # From VAE encoder + reparameterization\n",
    "        patient_inp_emb, _, _, _ = self.patient_vae(patient_inp)\n",
    "\n",
    "        # cl_drug_emb = self.drug_embedder(cl_drug)\n",
    "        patient_drug_emb = self.drug_embedder(patient_drug)\n",
    "\n",
    "        # cl_cat = torch.cat((cl_inp_emb, cl_drug_emb), axis = 1)\n",
    "        patient_cat = torch.cat((patient_inp_emb, patient_drug_emb), axis = 1)\n",
    "\n",
    "        # recist and audrc prediction\n",
    "        # audrc_pred = self.audrc_predictor(cl_cat)\n",
    "        recist_pred = self.recist_predictor(patient_cat)\n",
    "\n",
    "        return patient_cat, recist_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9422337-1db4-424f-bf24-1867699f5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train STL\n",
    "mtl_model = STL(cl_vae, patient_vae).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d1fde-2df6-4996-9e97-649c88adf9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = mtl_model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03fe9f9-17df-4ad3-bf86-01f92455d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_loop(model, cl_val_loader, patient_val_loader):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    true = []\n",
    "    for idx, batch in enumerate(patient_val_loader):\n",
    "        patient_inp = batch[0].to(device)\n",
    "        drug_inp = batch[1].to(device)\n",
    "        label = batch[2].to(device)\n",
    "        with torch.no_grad():\n",
    "            patient_emb, _, _, _ = model.patient_vae(patient_inp)\n",
    "            drug_emb = model.drug_embedder(drug_inp)\n",
    "            patient_cat = torch.cat((patient_emb, drug_emb), axis = 1)\n",
    "            pred = model.recist_predictor(patient_cat)\n",
    "            prediction.append(pred)\n",
    "            true.append(label)\n",
    "    predictions = torch.cat(prediction).view(-1, 1)\n",
    "    trues = torch.cat(true).view(-1, 1)\n",
    "    return nn.BCEWithLogitsLoss()(predictions, trues)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c00b81d6-8764-40e8-9ac3-625506b679a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss = 0.6706809545654098, val patient loss = 0.65804123878479\n",
      "Best val loss = 0.65804123878479\n",
      "Current val loss = 0.65804123878479\n",
      "Saved!\n",
      "Epoch 1: train loss = 0.5887035556088865, val patient loss = 0.5765764117240906\n",
      "Best val loss = 0.65804123878479\n",
      "Current val loss = 0.5765764117240906\n",
      "Saved!\n",
      "Epoch 2: train loss = 0.4171895946747337, val patient loss = 0.6558474898338318\n",
      "Best val loss = 0.5765764117240906\n",
      "Current val loss = 0.6558474898338318\n",
      "Increased count\n",
      "Epoch 3: train loss = 0.25568385670582455, val patient loss = 0.9221434593200684\n",
      "Best val loss = 0.5765764117240906\n",
      "Current val loss = 0.9221434593200684\n",
      "Increased count\n",
      "Epoch 4: train loss = 0.14655968515214576, val patient loss = 1.3216094970703125\n",
      "Best val loss = 0.5765764117240906\n",
      "Current val loss = 1.3216094970703125\n",
      "Increased count\n",
      "Converged\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "count = 0\n",
    "patient_val_losses = []\n",
    "for epoch in range(300):\n",
    "    mtl_model.train()\n",
    "    epoch_loss = []\n",
    "    for idx0, batch0 in enumerate(source_dataloader_train):\n",
    "        for idx1, batch1 in enumerate(target_dataloader_train):\n",
    "            optimizer.zero_grad()\n",
    "            cl_inp, cl_drug, patient_inp, patient_drug, audrc, recist = batch0[0].to(device), batch0[1].to(device), batch1[0].to(device), batch1[1].to(device), batch0[2].to(device), batch1[2].to(device)\n",
    "            patient_cat, recist_pred = mtl_model(cl_inp, cl_drug, patient_inp, patient_drug, audrc, recist)\n",
    "\n",
    "            # # align both\n",
    "            # coral_loss = coral(cl_cat, patient_cat)\n",
    "\n",
    "            # losses\n",
    "            # audrc_loss = nn.MSELoss()(audrc_pred.view(-1, 1), audrc.view(-1, 1))\n",
    "            recist_loss = nn.BCEWithLogitsLoss()(recist_pred.view(-1, 1), recist.view(-1, 1))\n",
    "\n",
    "            # total_loss = coral_loss + audrc_loss + recist_loss\n",
    "            # total_loss = audrc_loss + recist_loss\n",
    "            total_loss = recist_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss.append(total_loss.cpu().detach().numpy().item())\n",
    "\n",
    "    # get val loss\n",
    "    patient_val_loss = testing_loop(mtl_model, source_dataloader_val, target_dataloader_val)\n",
    "    patient_val_losses.append(patient_val_loss.item())\n",
    "    print(f\"Epoch {epoch}: train loss = {np.mean(epoch_loss)}, val patient loss = {patient_val_loss.item()}\")\n",
    "\n",
    "    if len(patient_val_losses) ==  1:\n",
    "        best_val_loss = patient_val_loss.item()\n",
    "\n",
    "    print(f\"Best val loss = {best_val_loss}\")\n",
    "    print(f\"Current val loss = {patient_val_loss.item()}\")\n",
    "\n",
    "    if patient_val_loss.item() <= best_val_loss: # minimize val loss\n",
    "        torch.save(mtl_model.state_dict(), f\"{folder_config['model_checkpoint_folder']}MTL_model_fold{fold}.pth\")\n",
    "        best_val_loss = patient_val_loss\n",
    "        print(\"Saved!\")\n",
    "        count = 0\n",
    "    else:\n",
    "        print(\"Increased count\")\n",
    "        count += 1\n",
    "\n",
    "    if count >= 3:\n",
    "        print(\"Converged\")\n",
    "        break\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c923bc63-018b-4f01-8527-be5582ca92e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference on cell line, drug pairs to get pseudolabels\n",
    "mtl_model_trained = STL(cl_vae, patient_vae).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab14b26c-f38d-46f0-912c-368154b76ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model_trained.load_state_dict(torch.load(f\"{folder_config['model_checkpoint_folder']}MTL_model_fold{fold}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "872518f4-b050-4f69-8711-53a4983b7caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STL(\n",
       "  (patient_vae): vae(\n",
       "    (mu_layer): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (sigma_layer): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (encoder): Sequential(\n",
       "      (enc-0): Linear(in_features=7776, out_features=512, bias=True)\n",
       "      (act-0): Tanh()\n",
       "      (enc-1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (act-1): ReLU()\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (-dec-0): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (-act-0): Tanh()\n",
       "      (dec-0): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (act-0): Tanh()\n",
       "      (dec-1): Linear(in_features=512, out_features=7776, bias=True)\n",
       "      (act-1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (drug_embedder): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (recist_predictor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "440e8ed7-bada-486f-b9a1-4461d83502ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded augmented CL data: (1193, 64)\n"
     ]
    }
   ],
   "source": [
    "# Load augmented cell lines and drug combos\n",
    "cl_augmented_df = load_augmented_cl_dataset(model_config[\"sample_id\"])\n",
    "train_val_cell_lines = list(cl_augmented_df.index)\n",
    "if model_config[\"experiment_id\"] == \"1B\":\n",
    "    drugs_with_fp = [model_config[\"experiment_settings\"].split(\", \")[0]] # extract out drug name\n",
    "elif model_config[\"experiment_id\"] == \"1A\":\n",
    "    drugs_with_fp = [model_config[\"experiment_settings\"]] # has only drug name\n",
    "else: # in 2A and 2B include all available drugs with fp\n",
    "    drugs_with_fp = list(drug_fp.index)\n",
    "possible_cl_drug_combinations = list(itertools.product(train_val_cell_lines, drugs_with_fp))\n",
    "possible_cl_drug_combinations_df = pd.DataFrame(possible_cl_drug_combinations, columns = [\"sample_id\", \"drug_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bef79039-e612-4a84-bbab-ecf5aa77a935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571447"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(possible_cl_drug_combinations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c372d539-d084-41e1-98d9-196959f24a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using data loaders to prevent execessive memory usage\n",
    "class CustomCellLineDataSetUnlabelled(TensorDataset):\n",
    "    def __init__(self, cl_augmented_df, drug_fp, possible_combinations): # possible_combinations must only consist of samples with drug name with a fingerprint\n",
    "        self.possible_combinations = possible_combinations\n",
    "        self.augmented_cl_df = cl_augmented_df\n",
    "        self.drug_fp = drug_fp\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_name, drug_name = self.possible_combinations[idx]\n",
    "        mut_profile = self.augmented_cl_df.loc[sample_name].values\n",
    "        drug_inp = self.drug_fp.loc[drug_name].values\n",
    "        return torch.FloatTensor(mut_profile), torch.FloatTensor(drug_inp)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.possible_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bc93e04-7a0a-4e9f-a340-4139b5f58fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible cl drug combos before pseudo label based filtering: \n",
      "571447\n"
     ]
    }
   ],
   "source": [
    "cl_aug_train_dataset = CustomCellLineDataSetUnlabelled(cl_augmented_df, drug_fp, possible_cl_drug_combinations)\n",
    "print(\"Number of possible cl drug combos before pseudo label based filtering: \")\n",
    "print(len(cl_aug_train_dataset))\n",
    "cl_aug_train_dataloader = DataLoader(cl_aug_train_dataset, batch_size=model_config[\"source_batch_size\"], shuffle=False) # to preserve order for later subset selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96040547-0805-4ae0-b96f-8605b3df00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_mtl(model, cl_aug_train_dataloader):\n",
    "    # forward on augmented cl data, via the patient embedder, and recist predictor\n",
    "    model.eval()\n",
    "    pseudo_y = []\n",
    "    for idx, batch in enumerate(cl_aug_train_dataloader):\n",
    "        patient_inp_emb = batch[0].to(device)\n",
    "        patient_drug = batch[1].to(device)\n",
    "        # print(patient_inp.shape)\n",
    "        with torch.no_grad():\n",
    "            # patient_inp_emb, _, _, _ = model.patient_vae(patient_inp)\n",
    "        \n",
    "            patient_drug_emb = model.drug_embedder(patient_drug)\n",
    "        \n",
    "            patient_cat = torch.cat((patient_inp_emb, patient_drug_emb), axis = 1)\n",
    "        \n",
    "            recist_pred = nn.Sigmoid()(model.recist_predictor(patient_cat)).view(-1, 1)\n",
    "            pseudo_y.append(recist_pred)\n",
    "\n",
    "    return torch.cat(pseudo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08561368-85f9-49d3-a30c-560ea7e09d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>drug_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>KIN001-260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>NSC-87877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>GNE-317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>NAVITOCLAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571442</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>SB590885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571443</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>STAUROSPORINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571444</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>TW 37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571445</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>ULIXERTINIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571446</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>ZM447439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>571447 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample_id      drug_name\n",
       "0       PR-132fPs      JW-7-24-1\n",
       "1       PR-132fPs     KIN001-260\n",
       "2       PR-132fPs      NSC-87877\n",
       "3       PR-132fPs        GNE-317\n",
       "4       PR-132fPs     NAVITOCLAX\n",
       "...           ...            ...\n",
       "571442  PR-2AxAKM       SB590885\n",
       "571443  PR-2AxAKM  STAUROSPORINE\n",
       "571444  PR-2AxAKM          TW 37\n",
       "571445  PR-2AxAKM    ULIXERTINIB\n",
       "571446  PR-2AxAKM       ZM447439\n",
       "\n",
       "[571447 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels_df = pd.DataFrame()\n",
    "pseudolabels_df[[\"sample_id\", \"drug_name\"]] = possible_cl_drug_combinations\n",
    "pseudolabels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d381395a-ee54-40b8-aede-e0e4ca96534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pseudo labels\n",
    "pseudolabels = inference_mtl(mtl_model_trained, cl_aug_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cebb0eb-e38b-47f1-8a17-6cf62c821b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudolabels_df[\"pseudolabels\"] = pseudolabels.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fc82a86-9881-4729-b99e-38f7a2b90250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>drug_name</th>\n",
       "      <th>pseudolabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "      <td>0.276278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>KIN001-260</td>\n",
       "      <td>0.325867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>NSC-87877</td>\n",
       "      <td>0.300446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>GNE-317</td>\n",
       "      <td>0.292867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>NAVITOCLAX</td>\n",
       "      <td>0.221668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571442</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>SB590885</td>\n",
       "      <td>0.471385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571443</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>STAUROSPORINE</td>\n",
       "      <td>0.405897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571444</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>TW 37</td>\n",
       "      <td>0.395958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571445</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>ULIXERTINIB</td>\n",
       "      <td>0.450421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571446</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>ZM447439</td>\n",
       "      <td>0.359631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>571447 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample_id      drug_name  pseudolabels\n",
       "0       PR-132fPs      JW-7-24-1      0.276278\n",
       "1       PR-132fPs     KIN001-260      0.325867\n",
       "2       PR-132fPs      NSC-87877      0.300446\n",
       "3       PR-132fPs        GNE-317      0.292867\n",
       "4       PR-132fPs     NAVITOCLAX      0.221668\n",
       "...           ...            ...           ...\n",
       "571442  PR-2AxAKM       SB590885      0.471385\n",
       "571443  PR-2AxAKM  STAUROSPORINE      0.405897\n",
       "571444  PR-2AxAKM          TW 37      0.395958\n",
       "571445  PR-2AxAKM    ULIXERTINIB      0.450421\n",
       "571446  PR-2AxAKM       ZM447439      0.359631\n",
       "\n",
       "[571447 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddcd2664-2855-40d5-9e70-c3967a9ba52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudolabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>571447.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.351494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.080653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.064604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.296515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.348547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.402838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.763780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pseudolabels\n",
       "count  571447.000000\n",
       "mean        0.351494\n",
       "std         0.080653\n",
       "min         0.064604\n",
       "25%         0.296515\n",
       "50%         0.348547\n",
       "75%         0.402838\n",
       "max         0.763780"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1db77148-fddb-418d-82e6-d2ece8b84267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary(prediction, lower_threshold, upper_threshold):\n",
    "    if prediction >= upper_threshold:\n",
    "        return 1\n",
    "    elif prediction < lower_threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1379f84-b423-44cc-a433-4138d400866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold and select confident samples\n",
    "if fold in [0, 1]:\n",
    "    pseudolabels_df[\"pseudolabels_binary\"] = pseudolabels_df[\"pseudolabels\"].apply(lambda x: convert_binary(x, 0.1, 0.7))\n",
    "else:\n",
    "    pseudolabels_df[\"pseudolabels_binary\"] = pseudolabels_df[\"pseudolabels\"].apply(lambda x: convert_binary(x, 0.1, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d2f79f7-4dd0-4b84-8118-003069194ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pseudolabels_binary\n",
       "0    121\n",
       "1     67\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels_df[pseudolabels_df.pseudolabels_binary != -1][\"pseudolabels_binary\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d6d04f1-c292-499d-81ec-94259f8e5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using data loaders to prevent execessive memory usage\n",
    "class CustomCombinedDataSetLabelled(TensorDataset):\n",
    "    def __init__(self, combined_df, cl_augmented_df, train_target_inputs_vae, drug_fp): # possible_combinations must only consist of samples with drug name with a fingerprint\n",
    "        self.sample_df = combined_df.reset_index(drop=True)\n",
    "        self.augmented_cl_df = cl_augmented_df\n",
    "        self.tcga_vae_df = train_target_inputs_vae[~train_target_inputs_vae.index.duplicated(keep=\"first\")]\n",
    "        self.drug_fp = drug_fp\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.sample_df.iloc[idx]\n",
    "        sample_name = row[\"sample_id\"]\n",
    "        drug_name = row[\"drug_name\"]\n",
    "        if sample_name in self.tcga_vae_df.index: # using VAE version instead of mutation profiles\n",
    "            mut_profile = self.tcga_vae_df.loc[sample_name].values\n",
    "        if sample_name in self.augmented_cl_df.index:\n",
    "            mut_profile = self.augmented_cl_df.loc[sample_name].values\n",
    "        drug_inp = self.drug_fp.loc[drug_name].values\n",
    "        response = row[\"recist\"]\n",
    "        return torch.FloatTensor(mut_profile), torch.FloatTensor(drug_inp), response\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a969eac-02ec-4ed3-8946-1807b867f0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of confident cl drug combinations with pseudolabels: \n",
      "(188, 3)\n",
      "Pseudo label distribution after majority vote:\n",
      "recist\n",
      "0    121\n",
      "1     67\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# non-abstained, confident pseudo labels\n",
    "confident_pseudolabels_df = pseudolabels_df[pseudolabels_df.pseudolabels_binary != -1]\n",
    "confident_pseudolabels_df_idx = confident_pseudolabels_df.index # used to filter out the possible drug combinations df\n",
    "\n",
    "confident_cl_drug_combinations_df = possible_cl_drug_combinations_df[possible_cl_drug_combinations_df.index.isin(confident_pseudolabels_df_idx)].copy()\n",
    "confident_cl_drug_combinations_df[\"recist\"] = list(confident_pseudolabels_df[\"pseudolabels_binary\"])\n",
    "print(\"Number of confident cl drug combinations with pseudolabels: \")\n",
    "print(confident_cl_drug_combinations_df.shape)\n",
    "print(\"Pseudo label distribution after majority vote:\")\n",
    "print(confident_cl_drug_combinations_df.recist.value_counts())\n",
    "\n",
    "# combine confident CL samples with pseudolabels, with TCGA train data\n",
    "combined_dataset_df = pd.concat([confident_cl_drug_combinations_df, train_target_data_merged[confident_cl_drug_combinations_df.columns]], axis=0)\n",
    "combined_dataset = CustomCombinedDataSetLabelled(combined_dataset_df, cl_augmented_df, train_target_inputs_vae, drug_fp)\n",
    "combined_dataloader = DataLoader(combined_dataset, batch_size=model_config[\"drp_batch_size\"], shuffle=True, worker_init_fn = seed_worker, generator = g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14069a7d-6388-4cbe-862e-5a4182d47ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.drug_embedder = nn.Sequential(nn.Linear(2048, 256), nn.ReLU(), nn.Linear(256, 64))\n",
    "        self.recist_predictor = nn.Sequential(nn.Linear(64 * 2, 16), nn.ReLU(), nn.Linear(16, 1))\n",
    "\n",
    "    def forward(self, patient_inp, patient_drug):\n",
    "        # patient_inp is 64 dim, drugs are 2048 dim\n",
    "        patient_drug_emb = self.drug_embedder(patient_drug)\n",
    "        patient_cat = torch.cat((patient_inp, patient_drug_emb), axis = 1)\n",
    "\n",
    "        # recist prediction\n",
    "        recist_pred = self.recist_predictor(patient_cat)\n",
    "\n",
    "        return recist_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d18f9a3-77cb-4495-ab80-1e743cb6d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_drp_model(model, patient_val_dataloader):\n",
    "    model.eval()\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    for idx, batch in enumerate(patient_val_dataloader):\n",
    "        with torch.no_grad():\n",
    "            patient_inp = batch[0].to(device)\n",
    "            patient_drug = batch[1].to(device)\n",
    "            label = batch[2].to(device)\n",
    "            y_preds.append(nn.Sigmoid()(model(patient_inp, patient_drug)).view(-1, 1))\n",
    "            y_trues.append(label.view(-1, 1))\n",
    "    return torch.cat(y_preds), torch.cat(y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23771145-ac47-40da-ba0a-7483119d585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_drp_model(model, train_dataloader, patient_val_dataloader, num_epochs=100, lr=1e-3):\n",
    "    \"\"\"\n",
    "    To train vanilla baseline model\n",
    "    \"\"\"\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    # training \n",
    "    val_corrs = []\n",
    "    count = 0\n",
    "    for i in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        if i > 10 and i % 10 == 0:\n",
    "            lr = lr/10\n",
    "            optim = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            optim.zero_grad()\n",
    "            patient_inp = batch[0].to(device)\n",
    "            patient_drug = batch[1].to(device)\n",
    "            label = batch[2].to(device)\n",
    "            y_pred = model(patient_inp, patient_drug).view(-1, 1)\n",
    "            loss = criterion(y_pred, label.view(-1, 1).to(device, dtype=torch.float32))\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        y_test_pred, test_y = inference_drp_model(model, patient_val_dataloader)\n",
    "        patient_corr = pearsonr(test_y.detach().cpu().numpy().reshape(-1), y_test_pred.detach().cpu().numpy().reshape(-1)).statistic + 1 # range in [0, 2]\n",
    "\n",
    "        val_corrs.append(patient_corr)\n",
    "        print(f\"Epoch {i}: Training loss: {np.mean(train_losses)} |  Validation correlation: {patient_corr}\")\n",
    "\n",
    "        # wandb.log({\n",
    "        #     f\"{model.model_name}_train_loss\": loss.detach().item(),\n",
    "        #     f\"validation_score\": patient_corr\n",
    "        # })\n",
    "        # convergence based on val score\n",
    "        if len(val_corrs) == 1: # first epoch\n",
    "            best_val_score = patient_corr\n",
    "\n",
    "        # save model\n",
    "        if model_config[\"model_save_criteria\"] in [\"val_AUROC\", \"val_AUPRC\", \"val_corr\"]: # maximise values\n",
    "            if patient_corr >= best_val_score:\n",
    "                best_val_score = patient_corr\n",
    "                # save model\n",
    "                print(\"Best model\")\n",
    "                torch.save(model.state_dict(), f\"{folder_config['model_checkpoint_folder']}/{model.model_name}_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.pth\")\n",
    "                count = 0 # reset count\n",
    "            else:\n",
    "                count += 1 # declining performance on validation data\n",
    "        else:\n",
    "            print(\"Unsupported metric for optimising\")\n",
    "            return\n",
    "        \n",
    "        if count >= 3:\n",
    "            print(\"Converged\")\n",
    "            break\n",
    "\n",
    "        # # convergence checking based on validation correlation\n",
    "        # if len(val_corrs) > 2:\n",
    "        #     if val_corrs[-1] < val_corrs[-2]: # maximise correlation\n",
    "        #         count += 1\n",
    "        #     else:\n",
    "        #         print(\"Best model\")\n",
    "        #         torch.save(model.state_dict(), f\"{folder_config['model_checkpoint_folder']}/{model.model_name}_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.pth\")\n",
    "        #         count = 0\n",
    "        # if len(val_corrs) == 1:\n",
    "        #     torch.save(model.state_dict(), f\"{folder_config['model_checkpoint_folder']}/{model.model_name}_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.pth\")\n",
    "        # if count > 3:\n",
    "        #     print(\"Converged\")\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "560e7b7f-4522-4201-9f22-2504cb7effc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_val_vae_dataset = CustomCombinedDataSetLabelled(val_target_data_merged, cl_augmented_df, val_target_inputs_vae, drug_fp)\n",
    "target_dataloader_val_vae = DataLoader(target_val_vae_dataset, batch_size=model_config[\"drp_batch_size\"], shuffle=True, worker_init_fn = seed_worker, generator = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9f5d853-f8a3-4435-988e-3eb5ffb83b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_val_vae_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36996f73-ddd9-4830-a6d8-7412e6f7625f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training loss: 0.6850144863128662 |  Validation correlation: 0.9942123732224866\n",
      "Best model\n",
      "Epoch 1: Training loss: 0.6738283932209015 |  Validation correlation: 0.9966617424074469\n",
      "Best model\n",
      "Epoch 2: Training loss: 0.6770106852054596 |  Validation correlation: 0.9989669083725039\n",
      "Best model\n",
      "Epoch 3: Training loss: 0.6697863340377808 |  Validation correlation: 1.0016466806320599\n",
      "Best model\n",
      "Epoch 4: Training loss: 0.6703705489635468 |  Validation correlation: 1.0044690591174343\n",
      "Best model\n",
      "Epoch 5: Training loss: 0.6645727455615997 |  Validation correlation: 1.007424507562135\n",
      "Best model\n",
      "Epoch 6: Training loss: 0.6648680865764618 |  Validation correlation: 1.0108358263005952\n",
      "Best model\n",
      "Epoch 7: Training loss: 0.6617021560668945 |  Validation correlation: 1.0144791873637415\n",
      "Best model\n",
      "Epoch 8: Training loss: 0.6616109311580658 |  Validation correlation: 1.0183098920534022\n",
      "Best model\n",
      "Epoch 9: Training loss: 0.6572049558162689 |  Validation correlation: 1.022834186414201\n",
      "Best model\n",
      "Epoch 10: Training loss: 0.658117026090622 |  Validation correlation: 1.0279543010663212\n",
      "Best model\n",
      "Epoch 11: Training loss: 0.6514687836170197 |  Validation correlation: 1.033706927931241\n",
      "Best model\n",
      "Epoch 12: Training loss: 0.6452982723712921 |  Validation correlation: 1.0401317947056792\n",
      "Best model\n",
      "Epoch 13: Training loss: 0.6503598093986511 |  Validation correlation: 1.0467287320820469\n",
      "Best model\n",
      "Epoch 14: Training loss: 0.6420632600784302 |  Validation correlation: 1.053755223995283\n",
      "Best model\n",
      "Epoch 15: Training loss: 0.6384482979774475 |  Validation correlation: 1.0617934276617318\n",
      "Best model\n",
      "Epoch 16: Training loss: 0.633537620306015 |  Validation correlation: 1.0704192438958577\n",
      "Best model\n",
      "Epoch 17: Training loss: 0.6270895898342133 |  Validation correlation: 1.0795203328443312\n",
      "Best model\n",
      "Epoch 18: Training loss: 0.6274673640727997 |  Validation correlation: 1.0892981904775487\n",
      "Best model\n",
      "Epoch 19: Training loss: 0.6233702898025513 |  Validation correlation: 1.0995536927925544\n",
      "Best model\n",
      "Epoch 20: Training loss: 0.6120763421058655 |  Validation correlation: 1.1004411981548297\n",
      "Best model\n",
      "Epoch 21: Training loss: 0.611002504825592 |  Validation correlation: 1.1013910155599365\n",
      "Best model\n",
      "Epoch 22: Training loss: 0.6183293461799622 |  Validation correlation: 1.1023230134118753\n",
      "Best model\n",
      "Epoch 23: Training loss: 0.6164076626300812 |  Validation correlation: 1.103246302895212\n",
      "Best model\n",
      "Epoch 24: Training loss: 0.6132789552211761 |  Validation correlation: 1.1041635540217472\n",
      "Best model\n",
      "Epoch 25: Training loss: 0.6069737076759338 |  Validation correlation: 1.105109998162556\n",
      "Best model\n",
      "Epoch 26: Training loss: 0.6125809550285339 |  Validation correlation: 1.1061069223654958\n",
      "Best model\n",
      "Epoch 27: Training loss: 0.6092339158058167 |  Validation correlation: 1.1071120378378698\n",
      "Best model\n",
      "Epoch 28: Training loss: 0.6157405376434326 |  Validation correlation: 1.1081060809533534\n",
      "Best model\n",
      "Epoch 29: Training loss: 0.6089687943458557 |  Validation correlation: 1.1090928080694826\n",
      "Best model\n",
      "Epoch 30: Training loss: 0.6031111180782318 |  Validation correlation: 1.1091917238925935\n",
      "Best model\n",
      "Epoch 31: Training loss: 0.6045787334442139 |  Validation correlation: 1.1092915990099135\n",
      "Best model\n",
      "Epoch 32: Training loss: 0.6043141186237335 |  Validation correlation: 1.1093902541448601\n",
      "Best model\n",
      "Epoch 33: Training loss: 0.619546502828598 |  Validation correlation: 1.1094884543802164\n",
      "Best model\n",
      "Epoch 34: Training loss: 0.6106869578361511 |  Validation correlation: 1.1095855984534533\n",
      "Best model\n",
      "Epoch 35: Training loss: 0.6083602905273438 |  Validation correlation: 1.1096864998836593\n",
      "Best model\n",
      "Epoch 36: Training loss: 0.6112436652183533 |  Validation correlation: 1.1097864622255422\n",
      "Best model\n",
      "Epoch 37: Training loss: 0.6133453249931335 |  Validation correlation: 1.109885411191824\n",
      "Best model\n",
      "Epoch 38: Training loss: 0.6104178726673126 |  Validation correlation: 1.1099830621818314\n",
      "Best model\n",
      "Epoch 39: Training loss: 0.6140338182449341 |  Validation correlation: 1.1100790433347125\n",
      "Best model\n",
      "Epoch 40: Training loss: 0.6127557754516602 |  Validation correlation: 1.1100894963550636\n",
      "Best model\n",
      "Epoch 41: Training loss: 0.6051714718341827 |  Validation correlation: 1.110098968585598\n",
      "Best model\n",
      "Epoch 42: Training loss: 0.6128742098808289 |  Validation correlation: 1.1101088229861311\n",
      "Best model\n",
      "Epoch 43: Training loss: 0.6103993952274323 |  Validation correlation: 1.1101183428514108\n",
      "Best model\n",
      "Epoch 44: Training loss: 0.6060147285461426 |  Validation correlation: 1.110128509871743\n",
      "Best model\n",
      "Epoch 45: Training loss: 0.6054736077785492 |  Validation correlation: 1.1101387155072824\n",
      "Best model\n",
      "Epoch 46: Training loss: 0.6080634295940399 |  Validation correlation: 1.1101485975436693\n",
      "Best model\n",
      "Epoch 47: Training loss: 0.6062687933444977 |  Validation correlation: 1.1101584705223484\n",
      "Best model\n",
      "Epoch 48: Training loss: 0.6132872104644775 |  Validation correlation: 1.1101679996848983\n",
      "Best model\n",
      "Epoch 49: Training loss: 0.6110793352127075 |  Validation correlation: 1.1101780348625396\n",
      "Best model\n",
      "Epoch 50: Training loss: 0.6072842478752136 |  Validation correlation: 1.1101791423728995\n",
      "Best model\n",
      "Epoch 51: Training loss: 0.6134115755558014 |  Validation correlation: 1.1101801287339177\n",
      "Best model\n",
      "Epoch 52: Training loss: 0.610618382692337 |  Validation correlation: 1.1101810499057954\n",
      "Best model\n",
      "Epoch 53: Training loss: 0.6134358048439026 |  Validation correlation: 1.1101820060136458\n",
      "Best model\n",
      "Epoch 54: Training loss: 0.6080119013786316 |  Validation correlation: 1.110182986558341\n",
      "Best model\n",
      "Epoch 55: Training loss: 0.609079897403717 |  Validation correlation: 1.1101840651094157\n",
      "Best model\n",
      "Epoch 56: Training loss: 0.6115978956222534 |  Validation correlation: 1.1101850211680422\n",
      "Best model\n",
      "Epoch 57: Training loss: 0.6050097644329071 |  Validation correlation: 1.1101859362963133\n",
      "Best model\n",
      "Epoch 58: Training loss: 0.6137173473834991 |  Validation correlation: 1.110186924159635\n",
      "Best model\n",
      "Epoch 59: Training loss: 0.6116775572299957 |  Validation correlation: 1.110187907006684\n",
      "Best model\n",
      "Epoch 60: Training loss: 0.6087587475776672 |  Validation correlation: 1.1101879911915775\n",
      "Best model\n",
      "Epoch 61: Training loss: 0.6101554036140442 |  Validation correlation: 1.1101881577682957\n",
      "Best model\n",
      "Epoch 62: Training loss: 0.609285831451416 |  Validation correlation: 1.110188244261615\n",
      "Best model\n",
      "Epoch 63: Training loss: 0.5994110107421875 |  Validation correlation: 1.1101882889322234\n",
      "Best model\n",
      "Epoch 64: Training loss: 0.6036071479320526 |  Validation correlation: 1.110188417596355\n",
      "Best model\n",
      "Epoch 65: Training loss: 0.6131304502487183 |  Validation correlation: 1.1101885162367942\n",
      "Best model\n",
      "Epoch 66: Training loss: 0.608536034822464 |  Validation correlation: 1.1101885444742825\n",
      "Best model\n",
      "Epoch 67: Training loss: 0.6113929152488708 |  Validation correlation: 1.1101886601400084\n",
      "Best model\n",
      "Epoch 68: Training loss: 0.6045253872871399 |  Validation correlation: 1.1101887245458095\n",
      "Best model\n",
      "Epoch 69: Training loss: 0.6132107377052307 |  Validation correlation: 1.1101888973724725\n",
      "Best model\n",
      "Epoch 70: Training loss: 0.6173533797264099 |  Validation correlation: 1.1101888973724725\n",
      "Best model\n",
      "Epoch 71: Training loss: 0.6112922728061676 |  Validation correlation: 1.1101888918814764\n",
      "Epoch 72: Training loss: 0.6113811433315277 |  Validation correlation: 1.1101888973724725\n",
      "Best model\n",
      "Epoch 73: Training loss: 0.6073861420154572 |  Validation correlation: 1.1101888973724725\n",
      "Best model\n",
      "Epoch 74: Training loss: 0.6030509173870087 |  Validation correlation: 1.1101888973724725\n",
      "Best model\n",
      "Epoch 75: Training loss: 0.608501136302948 |  Validation correlation: 1.110188879361712\n",
      "Epoch 76: Training loss: 0.6149327158927917 |  Validation correlation: 1.1101888846297072\n",
      "Epoch 77: Training loss: 0.6141375005245209 |  Validation correlation: 1.1101888973724725\n",
      "Best model\n",
      "Epoch 78: Training loss: 0.6061549186706543 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 79: Training loss: 0.6098448932170868 |  Validation correlation: 1.1101888973724725\n",
      "Epoch 80: Training loss: 0.6085613071918488 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 81: Training loss: 0.6108062863349915 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 82: Training loss: 0.6080278158187866 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 83: Training loss: 0.6106931269168854 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 84: Training loss: 0.6101426482200623 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 85: Training loss: 0.6089815199375153 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 86: Training loss: 0.6053478419780731 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 87: Training loss: 0.6113056242465973 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 88: Training loss: 0.6144174337387085 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 89: Training loss: 0.6076010167598724 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 90: Training loss: 0.6150545477867126 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 91: Training loss: 0.6057433485984802 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 92: Training loss: 0.6144457757472992 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 93: Training loss: 0.6084622740745544 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 94: Training loss: 0.6089774370193481 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 95: Training loss: 0.6093460023403168 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 96: Training loss: 0.6066917181015015 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 97: Training loss: 0.6069754660129547 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 98: Training loss: 0.61353400349617 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n",
      "Epoch 99: Training loss: 0.6129201948642731 |  Validation correlation: 1.1101889109171217\n",
      "Best model\n"
     ]
    }
   ],
   "source": [
    "# initialise the DRP NN \n",
    "nn_drp = DRP().to(device)\n",
    "nn_drp.model_name = \"DRP_model\"\n",
    "\n",
    "# Train DRP model\n",
    "train_drp_model(nn_drp, combined_dataloader, target_dataloader_val_vae, num_epochs=model_config[\"drp_epochs\"], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ee05dd6-c2e0-4803-a920-e4274dd3a8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_drp_trained = DRP().to(device)\n",
    "nn_drp_trained.model_name = \"DRP_model\"\n",
    "nn_drp_trained.load_state_dict(torch.load(f\"{folder_config['model_checkpoint_folder']}/{nn_drp_trained.model_name}_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86ee7d25-ddcb-4294-8fde-d79c355f40e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRP(\n",
       "  (drug_embedder): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (recist_predictor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_drp_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07c055fa-f86a-4e98-be48-2ee6a717c0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vae_feat0</th>\n",
       "      <th>vae_feat1</th>\n",
       "      <th>vae_feat2</th>\n",
       "      <th>vae_feat3</th>\n",
       "      <th>vae_feat4</th>\n",
       "      <th>vae_feat5</th>\n",
       "      <th>vae_feat6</th>\n",
       "      <th>vae_feat7</th>\n",
       "      <th>vae_feat8</th>\n",
       "      <th>vae_feat9</th>\n",
       "      <th>...</th>\n",
       "      <th>vae_feat54</th>\n",
       "      <th>vae_feat55</th>\n",
       "      <th>vae_feat56</th>\n",
       "      <th>vae_feat57</th>\n",
       "      <th>vae_feat58</th>\n",
       "      <th>vae_feat59</th>\n",
       "      <th>vae_feat60</th>\n",
       "      <th>vae_feat61</th>\n",
       "      <th>vae_feat62</th>\n",
       "      <th>vae_feat63</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P-0021780-T01-IM6</th>\n",
       "      <td>0.753870</td>\n",
       "      <td>2.671893</td>\n",
       "      <td>-0.065950</td>\n",
       "      <td>-0.772220</td>\n",
       "      <td>0.109030</td>\n",
       "      <td>-0.369968</td>\n",
       "      <td>-3.230829</td>\n",
       "      <td>4.487302</td>\n",
       "      <td>-2.270967</td>\n",
       "      <td>0.570039</td>\n",
       "      <td>...</td>\n",
       "      <td>1.957493</td>\n",
       "      <td>-1.881829</td>\n",
       "      <td>-3.369706</td>\n",
       "      <td>2.474177</td>\n",
       "      <td>3.400534</td>\n",
       "      <td>0.229281</td>\n",
       "      <td>-0.453274</td>\n",
       "      <td>-0.959082</td>\n",
       "      <td>-0.787572</td>\n",
       "      <td>2.721531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A5-A1OH</th>\n",
       "      <td>-3.121249</td>\n",
       "      <td>0.396491</td>\n",
       "      <td>-1.609849</td>\n",
       "      <td>2.203196</td>\n",
       "      <td>0.017517</td>\n",
       "      <td>2.055745</td>\n",
       "      <td>0.465779</td>\n",
       "      <td>1.823159</td>\n",
       "      <td>0.577330</td>\n",
       "      <td>-0.769108</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.059080</td>\n",
       "      <td>-1.022598</td>\n",
       "      <td>3.021566</td>\n",
       "      <td>3.092883</td>\n",
       "      <td>2.320927</td>\n",
       "      <td>-2.494244</td>\n",
       "      <td>0.989937</td>\n",
       "      <td>-2.556913</td>\n",
       "      <td>-4.543158</td>\n",
       "      <td>-1.736792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-DX-A7EQ</th>\n",
       "      <td>-1.464140</td>\n",
       "      <td>-1.723419</td>\n",
       "      <td>3.162946</td>\n",
       "      <td>-0.389088</td>\n",
       "      <td>0.841693</td>\n",
       "      <td>-1.140654</td>\n",
       "      <td>1.063845</td>\n",
       "      <td>-3.504539</td>\n",
       "      <td>-1.551661</td>\n",
       "      <td>0.125888</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.422489</td>\n",
       "      <td>-6.378718</td>\n",
       "      <td>-2.549912</td>\n",
       "      <td>-0.597865</td>\n",
       "      <td>-1.969940</td>\n",
       "      <td>-1.956433</td>\n",
       "      <td>1.194958</td>\n",
       "      <td>2.477910</td>\n",
       "      <td>0.117304</td>\n",
       "      <td>0.970536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-FB-A5VM</th>\n",
       "      <td>-1.489462</td>\n",
       "      <td>-2.549048</td>\n",
       "      <td>1.081577</td>\n",
       "      <td>-0.366478</td>\n",
       "      <td>2.826008</td>\n",
       "      <td>3.115010</td>\n",
       "      <td>0.557466</td>\n",
       "      <td>-0.623550</td>\n",
       "      <td>3.350868</td>\n",
       "      <td>-4.735223</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134958</td>\n",
       "      <td>-0.607584</td>\n",
       "      <td>-0.990438</td>\n",
       "      <td>0.835826</td>\n",
       "      <td>-1.021624</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>0.075469</td>\n",
       "      <td>-0.297340</td>\n",
       "      <td>-2.167166</td>\n",
       "      <td>2.701391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_DS_bkm_035_T</th>\n",
       "      <td>-1.819688</td>\n",
       "      <td>-0.556152</td>\n",
       "      <td>1.155614</td>\n",
       "      <td>0.839682</td>\n",
       "      <td>0.148615</td>\n",
       "      <td>-2.107968</td>\n",
       "      <td>-0.875630</td>\n",
       "      <td>2.340693</td>\n",
       "      <td>-4.234872</td>\n",
       "      <td>-1.195544</td>\n",
       "      <td>...</td>\n",
       "      <td>4.688541</td>\n",
       "      <td>0.788113</td>\n",
       "      <td>1.890439</td>\n",
       "      <td>-1.989851</td>\n",
       "      <td>2.756450</td>\n",
       "      <td>2.734972</td>\n",
       "      <td>0.252763</td>\n",
       "      <td>2.669675</td>\n",
       "      <td>0.342463</td>\n",
       "      <td>-0.071207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-GN-A8LK</th>\n",
       "      <td>0.636500</td>\n",
       "      <td>-2.450130</td>\n",
       "      <td>0.376215</td>\n",
       "      <td>-1.003094</td>\n",
       "      <td>1.821947</td>\n",
       "      <td>-2.638656</td>\n",
       "      <td>0.970507</td>\n",
       "      <td>-0.832626</td>\n",
       "      <td>0.848191</td>\n",
       "      <td>-2.101937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115783</td>\n",
       "      <td>-1.103842</td>\n",
       "      <td>3.154271</td>\n",
       "      <td>1.583811</td>\n",
       "      <td>1.738071</td>\n",
       "      <td>-0.124071</td>\n",
       "      <td>-2.681928</td>\n",
       "      <td>-0.047339</td>\n",
       "      <td>0.919442</td>\n",
       "      <td>0.729093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-EX-A3L1</th>\n",
       "      <td>-2.921046</td>\n",
       "      <td>-0.991886</td>\n",
       "      <td>1.129316</td>\n",
       "      <td>0.579603</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>-0.955165</td>\n",
       "      <td>1.972070</td>\n",
       "      <td>2.286034</td>\n",
       "      <td>-0.743556</td>\n",
       "      <td>-0.991338</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029625</td>\n",
       "      <td>1.662122</td>\n",
       "      <td>-4.011302</td>\n",
       "      <td>2.389884</td>\n",
       "      <td>-1.478411</td>\n",
       "      <td>2.402270</td>\n",
       "      <td>1.379301</td>\n",
       "      <td>1.346545</td>\n",
       "      <td>1.760828</td>\n",
       "      <td>-2.319649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3A-A9IC</th>\n",
       "      <td>-1.340715</td>\n",
       "      <td>2.228920</td>\n",
       "      <td>1.564497</td>\n",
       "      <td>0.221986</td>\n",
       "      <td>2.836560</td>\n",
       "      <td>1.148562</td>\n",
       "      <td>1.103388</td>\n",
       "      <td>3.092237</td>\n",
       "      <td>1.349141</td>\n",
       "      <td>2.581805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.760562</td>\n",
       "      <td>6.891579</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>-1.765402</td>\n",
       "      <td>2.736322</td>\n",
       "      <td>1.370849</td>\n",
       "      <td>-1.050812</td>\n",
       "      <td>-2.966963</td>\n",
       "      <td>-1.720458</td>\n",
       "      <td>3.103694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-0020359-T01-IM6</th>\n",
       "      <td>-4.525671</td>\n",
       "      <td>-0.685367</td>\n",
       "      <td>-0.532490</td>\n",
       "      <td>0.576549</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>3.710602</td>\n",
       "      <td>0.035627</td>\n",
       "      <td>0.733681</td>\n",
       "      <td>0.486619</td>\n",
       "      <td>-3.179904</td>\n",
       "      <td>...</td>\n",
       "      <td>3.193052</td>\n",
       "      <td>0.875511</td>\n",
       "      <td>0.377146</td>\n",
       "      <td>1.512649</td>\n",
       "      <td>0.711286</td>\n",
       "      <td>1.004701</td>\n",
       "      <td>1.800535</td>\n",
       "      <td>0.786677</td>\n",
       "      <td>-0.120188</td>\n",
       "      <td>-2.311344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-VS-A9V1</th>\n",
       "      <td>0.200169</td>\n",
       "      <td>-2.524173</td>\n",
       "      <td>1.951373</td>\n",
       "      <td>2.706040</td>\n",
       "      <td>-0.263011</td>\n",
       "      <td>-2.403155</td>\n",
       "      <td>0.258335</td>\n",
       "      <td>-0.126816</td>\n",
       "      <td>-5.800976</td>\n",
       "      <td>3.055504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139157</td>\n",
       "      <td>0.890854</td>\n",
       "      <td>0.913867</td>\n",
       "      <td>-4.952621</td>\n",
       "      <td>2.568263</td>\n",
       "      <td>-1.683523</td>\n",
       "      <td>-1.199820</td>\n",
       "      <td>1.678121</td>\n",
       "      <td>1.478146</td>\n",
       "      <td>0.611290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>487 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   vae_feat0  vae_feat1  vae_feat2  vae_feat3  vae_feat4  \\\n",
       "sample_id                                                                  \n",
       "P-0021780-T01-IM6   0.753870   2.671893  -0.065950  -0.772220   0.109030   \n",
       "TCGA-A5-A1OH       -3.121249   0.396491  -1.609849   2.203196   0.017517   \n",
       "TCGA-DX-A7EQ       -1.464140  -1.723419   3.162946  -0.389088   0.841693   \n",
       "TCGA-FB-A5VM       -1.489462  -2.549048   1.081577  -0.366478   2.826008   \n",
       "s_DS_bkm_035_T     -1.819688  -0.556152   1.155614   0.839682   0.148615   \n",
       "...                      ...        ...        ...        ...        ...   \n",
       "TCGA-GN-A8LK        0.636500  -2.450130   0.376215  -1.003094   1.821947   \n",
       "TCGA-EX-A3L1       -2.921046  -0.991886   1.129316   0.579603   0.016393   \n",
       "TCGA-3A-A9IC       -1.340715   2.228920   1.564497   0.221986   2.836560   \n",
       "P-0020359-T01-IM6  -4.525671  -0.685367  -0.532490   0.576549   0.010061   \n",
       "TCGA-VS-A9V1        0.200169  -2.524173   1.951373   2.706040  -0.263011   \n",
       "\n",
       "                   vae_feat5  vae_feat6  vae_feat7  vae_feat8  vae_feat9  ...  \\\n",
       "sample_id                                                                 ...   \n",
       "P-0021780-T01-IM6  -0.369968  -3.230829   4.487302  -2.270967   0.570039  ...   \n",
       "TCGA-A5-A1OH        2.055745   0.465779   1.823159   0.577330  -0.769108  ...   \n",
       "TCGA-DX-A7EQ       -1.140654   1.063845  -3.504539  -1.551661   0.125888  ...   \n",
       "TCGA-FB-A5VM        3.115010   0.557466  -0.623550   3.350868  -4.735223  ...   \n",
       "s_DS_bkm_035_T     -2.107968  -0.875630   2.340693  -4.234872  -1.195544  ...   \n",
       "...                      ...        ...        ...        ...        ...  ...   \n",
       "TCGA-GN-A8LK       -2.638656   0.970507  -0.832626   0.848191  -2.101937  ...   \n",
       "TCGA-EX-A3L1       -0.955165   1.972070   2.286034  -0.743556  -0.991338  ...   \n",
       "TCGA-3A-A9IC        1.148562   1.103388   3.092237   1.349141   2.581805  ...   \n",
       "P-0020359-T01-IM6   3.710602   0.035627   0.733681   0.486619  -3.179904  ...   \n",
       "TCGA-VS-A9V1       -2.403155   0.258335  -0.126816  -5.800976   3.055504  ...   \n",
       "\n",
       "                   vae_feat54  vae_feat55  vae_feat56  vae_feat57  vae_feat58  \\\n",
       "sample_id                                                                       \n",
       "P-0021780-T01-IM6    1.957493   -1.881829   -3.369706    2.474177    3.400534   \n",
       "TCGA-A5-A1OH        -1.059080   -1.022598    3.021566    3.092883    2.320927   \n",
       "TCGA-DX-A7EQ        -1.422489   -6.378718   -2.549912   -0.597865   -1.969940   \n",
       "TCGA-FB-A5VM         1.134958   -0.607584   -0.990438    0.835826   -1.021624   \n",
       "s_DS_bkm_035_T       4.688541    0.788113    1.890439   -1.989851    2.756450   \n",
       "...                       ...         ...         ...         ...         ...   \n",
       "TCGA-GN-A8LK         0.115783   -1.103842    3.154271    1.583811    1.738071   \n",
       "TCGA-EX-A3L1         1.029625    1.662122   -4.011302    2.389884   -1.478411   \n",
       "TCGA-3A-A9IC        -0.760562    6.891579    0.049777   -1.765402    2.736322   \n",
       "P-0020359-T01-IM6    3.193052    0.875511    0.377146    1.512649    0.711286   \n",
       "TCGA-VS-A9V1        -0.139157    0.890854    0.913867   -4.952621    2.568263   \n",
       "\n",
       "                   vae_feat59  vae_feat60  vae_feat61  vae_feat62  vae_feat63  \n",
       "sample_id                                                                      \n",
       "P-0021780-T01-IM6    0.229281   -0.453274   -0.959082   -0.787572    2.721531  \n",
       "TCGA-A5-A1OH        -2.494244    0.989937   -2.556913   -4.543158   -1.736792  \n",
       "TCGA-DX-A7EQ        -1.956433    1.194958    2.477910    0.117304    0.970536  \n",
       "TCGA-FB-A5VM        -0.112169    0.075469   -0.297340   -2.167166    2.701391  \n",
       "s_DS_bkm_035_T       2.734972    0.252763    2.669675    0.342463   -0.071207  \n",
       "...                       ...         ...         ...         ...         ...  \n",
       "TCGA-GN-A8LK        -0.124071   -2.681928   -0.047339    0.919442    0.729093  \n",
       "TCGA-EX-A3L1         2.402270    1.379301    1.346545    1.760828   -2.319649  \n",
       "TCGA-3A-A9IC         1.370849   -1.050812   -2.966963   -1.720458    3.103694  \n",
       "P-0020359-T01-IM6    1.004701    1.800535    0.786677   -0.120188   -2.311344  \n",
       "TCGA-VS-A9V1        -1.683523   -1.199820    1.678121    1.478146    0.611290  \n",
       "\n",
       "[487 rows x 64 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_inputs_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52b8761a-d220-49fc-9248-c02e6b747214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target test\n",
    "target_test_vae_dataset = CustomCombinedDataSetLabelled(test_target_data_merged, cl_augmented_df, test_target_inputs_vae, drug_fp)\n",
    "target_dataloader_test_vae = DataLoader(target_test_vae_dataset, batch_size=model_config[\"drp_batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a1e8185-b3b8-4c54-b7dc-eebe8588c7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_test_vae_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ded16e37-2956-4af4-b552-491b84598071",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred, test_y = inference_drp_model(nn_drp_trained, target_dataloader_test_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b9ae7e6-920a-4221-ab48-cf612c0257ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame()\n",
    "res_df[\"y_pred\"] = y_test_pred.cpu().detach().numpy().reshape(-1)\n",
    "res_df[\"y_true\"] = test_y.cpu().detach().numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1db10d4e-0905-4128-8d00-daea2d95f20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.386800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.485448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.459732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.417941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.441921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.503851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.482720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.450225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.355868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.338471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_pred  y_true\n",
       "0    0.386800       1\n",
       "1    0.485448       0\n",
       "2    0.459732       0\n",
       "3    0.417941       0\n",
       "4    0.441921       0\n",
       "..        ...     ...\n",
       "108  0.503851       0\n",
       "109  0.482720       1\n",
       "110  0.450225       0\n",
       "111  0.355868       0\n",
       "112  0.338471       1\n",
       "\n",
       "[113 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47d48405-e030-4861-a6e3-f7a343d899a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17d22d8d-3c21-4fef-8886-67c71a7ba134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5440051020408163"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(res_df[\"y_true\"], res_df[\"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1f4bab5-9f29-4c64-8661-b55ca8c1e728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.529498208070906"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(res_df[\"y_true\"], res_df[\"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f30123e-4b76-4a28-a4fb-755ebf5e841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv(f\"{folder_config['model_checkpoint_folder']}/prediction_patients_val_corr_2A_ALL_fold{fold}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e93266-71bb-497c-98bd-4167d72c62f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:systematic_assessment] *",
   "language": "python",
   "name": "conda-env-systematic_assessment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
