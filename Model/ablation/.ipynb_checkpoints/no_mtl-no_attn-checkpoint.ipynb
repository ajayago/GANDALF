{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b3655f4-7a07-455e-8b67-246673d94d83",
   "metadata": {},
   "source": [
    "Remove MTL in downstream, i.e. STL with patient data.\n",
    "\n",
    "Remove attention in pretraining, use `ablation_noattn` folder for pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8435a94-3245-49ab-b4e9-3cd8f1562bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajayago/anaconda3/envs/systematic_assessment/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6482d30-3ef6-4263-baa0-779f7c93c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import yaml\n",
    "import pprint\n",
    "import os\n",
    "import wandb\n",
    "import sys\n",
    "import random\n",
    "from scipy.stats import mode, pearsonr\n",
    "import pickle\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.gaussian_multinomial_diffusion import GaussianMultinomialDiffusion\n",
    "from src.modules import MLPDiffusion\n",
    "from src.vae_model import vae\n",
    "from src.loss_functions import get_kld_loss, coral\n",
    "from model_definition import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423d4470-75ea-4b9a-b014-0b99e1b94a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f87a87-38a2-4807-8433-aeda1621fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from ../experiment_settings_yaml/ablation/model_config_2A_annotated_mutations_v7_fold1_noattn.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjayagopalaishwarya\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ajayago/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb2487b7fb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global variables\n",
    "\n",
    "CONFIG_PATH = f\"../experiment_settings_yaml/ablation/model_config_2A_annotated_mutations_v7_fold{fold}_noattn.yaml\" # model config path\n",
    "pretty_print = pprint.PrettyPrinter()\n",
    "print(f\"Loading config from {CONFIG_PATH}\")\n",
    "config = yaml.safe_load(open(CONFIG_PATH))\n",
    "model_config = config[\"model_hyperparams\"]\n",
    "folder_config = config[\"folder_config\"]\n",
    "wandb_config = config[\"wandb_config\"]\n",
    "wandb_config[\"project_name\"] = wandb_config[\"project_name\"] + f\"-{model_config['experiment_id']}-{model_config['experiment_settings']}-fold{model_config['sample_id']}\" # updates wandb project name for ease of monitoring and logging.\n",
    "device = torch.device(f\"cuda:{model_config['device']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "genes_324 = list(pd.read_csv(f\"{folder_config['data_folder']}/raw/metadata/gene2ind.txt\", header=None)[0])\n",
    "drug_fp = pd.read_csv(f\"{folder_config['data_folder']}/raw/metadata/drug_morgan_fingerprints.csv\", index_col=0)\n",
    "suffixes = [\"_piu_max\", \"_piu_sum\", \"_piu_mean\", \"_piu_count\",\n",
    "            \"_lu_max\", \"_lu_sum\", \"_lu_mean\", \"_lu_count\",\n",
    "            \"_ncu_max\", \"_ncu_sum\", \"_ncu_mean\", '_ncu_count',\n",
    "            \"_pathogenic_max\", \"_pathogenic_sum\", \"_pathogenic_mean\", \"_pathogenic_count\",\n",
    "            \"_vus_max\", \"_vus_sum\", \"_vus_mean\", \"_vus_count\",\n",
    "            \"_benign_max\", \"_benign_sum\", \"_benign_mean\", \"_benign_count\"\n",
    "           ]\n",
    "genes_7776 = []\n",
    "for s in suffixes:\n",
    "    for g in list(pd.read_csv(f\"{folder_config['data_folder']}/raw/metadata/gene2ind.txt\", header=None)[0]):\n",
    "        genes_7776.append(f\"{g}{s}\")\n",
    "\n",
    "# setting up wandb\n",
    "os.environ[\"WANDB_CACHE_DIR\"] = wandb_config[\"wandb_cache_dir\"]\n",
    "os.environ[\"WANDB_DIR\"] = wandb_config[\"wandb_cache_dir\"]\n",
    "wandb.login(key=wandb_config[\"api_key\"])\n",
    "\n",
    "# seeding\n",
    "torch.manual_seed(model_config[\"seed\"])\n",
    "random.seed(model_config[\"seed\"])\n",
    "np.random.seed(model_config[\"seed\"])\n",
    "# reproducibility in data loading - https://pytorch.org/docs/stable/notes/randomness.html\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(model_config[\"seed\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc87d5a-fc7b-4171-994d-5ef2d10cc1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_folder = \"/data/ajayago/papers_data/DiffDRP_v7/run_files/saved_model_annotated_mutations/ablation/ablation_noattn/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d0269e6-03fe-49c4-b22b-fe6da00c700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass samples through the VAE and DDPM network, till just before VAE decoder\n",
    "def vae_decoder_input(df, vae, diff_model):\n",
    "    \"\"\"\n",
    "    Takes input df, pretrained vae and diffusion model as inputs, runs forward pass till VAE decoder\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch = torch.tensor(df.values) # convert to torch tensor\n",
    "        inp_vae = batch.to(device, dtype=torch.float32)\n",
    "        inp, mu, logvar, _ = vae(inp_vae) # From VAE encoder + reparameterization\n",
    "        \n",
    "        noise = torch.randn_like(inp) # this is the label we use   \n",
    "        b = inp.shape[0]\n",
    "        t = (torch.ones((b,)) * 700).long().to(device) # fixing time steps to 700\n",
    "        pt = torch.ones_like(t).float() / diff_model.num_timesteps\n",
    "        inp_t = diff_model.gaussian_q_sample(inp, t, noise) # forward process with cell line model encoder\n",
    "        \n",
    "        model_out = diff_model._denoise_fn(inp_t, t) # predicted epsilon from patient decoder\n",
    "    \n",
    "        # predict inp from noise using patient model\n",
    "        inp_pred = diff_model._predict_xstart_from_eps(inp_t, t, model_out)\n",
    "\n",
    "    return inp_pred.detach().cpu().numpy()\n",
    "\n",
    "def load_pretrained_models():\n",
    "    pretrained = torch.load(f\"{pretrained_folder}/best_pretrained_validation_loss_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.pth\")\n",
    "    is_real = True if model_config[\"input_data_type\"] == \"binary_mutations\" else False\n",
    "    # patients\n",
    "    patient_vae = vae(input_dim=model_config[\"feature_num\"], k_list=model_config[\"patient_vae_k_list\"], actf_list=model_config[\"patient_vae_actf_list\"], is_real=is_real).to(device)\n",
    "    tcga_mlp_diffusion_model = MLPDiffusion(d_in=model_config[\"patient_vae_k_list\"][-1]//2, num_classes=0, is_y_cond=False, rtdl_params={\"d_layers\": [model_config[\"patient_vae_k_list\"][-1]//4], \"dropout\": model_config[\"dropout\"]}).to(device)\n",
    "    tcga_diff_model = GaussianMultinomialDiffusion(num_classes=np.array([0]), num_numerical_features=model_config[\"patient_vae_k_list\"][-1]//2, denoise_fn=tcga_mlp_diffusion_model, device=device)#.to(device)\n",
    "    tcga_diff_model.load_state_dict(pretrained[\"patient_diff_model\"])\n",
    "    patient_vae.load_state_dict(pretrained[\"patient_vae_conditioned\"])\n",
    "    # cell lines\n",
    "    cl_vae = vae(input_dim=model_config[\"feature_num\"], k_list=model_config[\"cl_vae_k_list\"], actf_list=model_config[\"cl_vae_actf_list\"], is_real=is_real).to(device)\n",
    "    cl_mlp_diffusion_model = MLPDiffusion(d_in=model_config[\"cl_vae_k_list\"][-1]//2, num_classes=0, is_y_cond=False, rtdl_params={\"d_layers\": [model_config[\"cl_vae_k_list\"][-1]//4], \"dropout\": model_config[\"dropout\"]}).to(device)\n",
    "    cl_diff_model = GaussianMultinomialDiffusion(num_classes=np.array([0]), num_numerical_features=model_config[\"cl_vae_k_list\"][-1]//2, denoise_fn=cl_mlp_diffusion_model, device=device)#.to(device)\n",
    "    cl_diff_model.load_state_dict(pretrained[\"cl_diff_model\"])\n",
    "    cl_vae.load_state_dict(pretrained[\"cl_vae_conditioned\"])\n",
    "    return cl_diff_model, cl_vae, tcga_diff_model, patient_vae\n",
    "\n",
    "def load_datasets(sample_id):\n",
    "    \"\"\"\n",
    "    Takes sample_id as input, loads source and target train, validation and test splits (predefined files from Processing folder).\n",
    "    \"\"\"\n",
    "    data_dir = folder_config[\"data_folder\"] + \"input_types/\"\n",
    "    # navigate based on input type\n",
    "    if model_config[\"input_data_type\"] == \"binary_mutations\":\n",
    "        data_dir = data_dir + \"raw_mutations/\"\n",
    "        features2select = genes_324  # inclusive of Morgan drug fingerprints of 2048 dim\n",
    "    elif model_config[\"input_data_type\"] == \"annotated_mutations\":\n",
    "        data_dir = data_dir + \"annotated_mutations/\"\n",
    "        features2select = genes_7776  # inclusive of Morgan drug fingerprints of 2048 dim\n",
    "    elif model_config[\"input_data_type\"] == \"transformer_inputs\": # processed by PREDICT-AI transformer embedder\n",
    "        data_dir = data_dir + \"transformer_inputs_transformed_797/\"\n",
    "        features2select = [f\"transformer_embedded_{i}\" for i in range(797)] # after transformer embedding\n",
    "    else:\n",
    "        print(\"Unsupported input type!\")\n",
    "        return\n",
    "    \n",
    "    # navigate based on experiment id\n",
    "    if model_config[\"experiment_id\"] == \"1A\":\n",
    "        data_dir = data_dir + \"Experiment1/SettingA/\"\n",
    "    elif model_config[\"experiment_id\"] == \"1B\":\n",
    "        data_dir = data_dir + \"Experiment1/SettingB/\"\n",
    "    elif model_config[\"experiment_id\"] == \"2A\":\n",
    "        data_dir = data_dir + \"Experiment2/SettingA/\"\n",
    "    elif model_config[\"experiment_id\"] == \"2B\":\n",
    "        data_dir = data_dir + \"Experiment2/SettingB/\"\n",
    "    else:\n",
    "        print(\"Unsupported experiment ID!\")\n",
    "        return\n",
    "    \n",
    "    # load the fold based on sample_id - Note: cell lines have only 1 fold (fold 0)\n",
    "    with open(f\"{data_dir}/cell_lines_fold0_processed.pkl\", \"rb\") as f:\n",
    "        source_data = pickle.load(f)\n",
    "\n",
    "    with open(f\"{data_dir}/patients_fold{sample_id}_processed.pkl\", \"rb\") as f:\n",
    "        target_data = pickle.load(f)\n",
    "\n",
    "    # load pretrained TCGA VAE and diffusion models\n",
    "    # pass data points through patient DDPM and get the input to VAE decoder for DRP\n",
    "    cl_diff_model, cl_vae, tcga_diff_model, patient_vae = load_pretrained_models()\n",
    "    \n",
    "    # select data based on experiment settings \n",
    "    # Can be CISPLATIN, PACLITAXEL, FLUOROURACIL, SORAFENIB for 1A, CISPLATIN, TCGA-CESC; CISPLATIN, TCGA-HNSC; PACLITAXEL, TCGA-BRCA; FLUOROURACIL, TCGA-STAD for 1B\n",
    "    # ALL for 2A, TCGA-BRCA, TCGA-CESC, TCGA-HNSC, TCGA-STAD for 2B\n",
    "    if model_config[\"experiment_id\"] in [\"1A\", \"2B\"]:\n",
    "        setting = model_config[\"experiment_settings\"]\n",
    "        train_source_data, val_source_data, test_source_data = source_data[\"train\"][setting], source_data[\"val\"][setting], source_data[\"test\"][setting]\n",
    "        train_target_data, val_target_data, test_target_data = target_data[\"train\"][setting], target_data[\"val\"][setting], target_data[\"test\"][setting]\n",
    "    elif model_config[\"experiment_id\"] == \"1B\":\n",
    "        setting = (model_config[\"experiment_settings\"].split(\", \")[0], model_config[\"experiment_settings\"].split(\", \")[1], \"TCGA\")\n",
    "        train_source_data, val_source_data, test_source_data = source_data[\"train\"][setting], source_data[\"val\"][setting], source_data[\"test\"][setting]\n",
    "        train_target_data, val_target_data, test_target_data = target_data[\"train\"][setting], target_data[\"val\"][setting], target_data[\"test\"][setting]\n",
    "    elif model_config[\"experiment_id\"] == \"2A\":\n",
    "        train_source_data, val_source_data, test_source_data = source_data[\"train\"], source_data[\"val\"], source_data[\"test\"]\n",
    "        train_target_data, val_target_data, test_target_data = target_data[\"train\"], target_data[\"val\"], target_data[\"test\"]\n",
    "    else:\n",
    "        print(\"Unsupported experiment settings and ID\")\n",
    "        return\n",
    "    \n",
    "    # merge dataframes with drug Morgan fingprint dataframes\n",
    "    train_source_data_merged = train_source_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "    val_source_data_merged = val_source_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "    test_source_data_merged = test_source_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "\n",
    "    train_target_data_merged = train_target_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "    val_target_data_merged = val_target_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "    test_target_data_merged = test_target_data.merge(drug_fp, left_on=\"drug_name\", right_on=drug_fp.index)\n",
    "\n",
    "    assert train_source_data_merged.shape[0] == train_source_data.shape[0], \"Train source data loss after merge!\"\n",
    "    assert val_source_data_merged.shape[0] == val_source_data.shape[0], \"Val source data loss after merge!\"\n",
    "    assert test_source_data_merged.shape[0] == test_source_data.shape[0], \"Test source data loss after merge!\"\n",
    "    assert train_target_data_merged.shape[0] == train_target_data.shape[0], \"Train target data loss after merge!\"\n",
    "    assert val_target_data_merged.shape[0] == val_target_data.shape[0], \"Val target data loss after merge!\"\n",
    "    assert test_target_data_merged.shape[0] == test_target_data.shape[0], \"Test target data loss after merge!\"\n",
    "\n",
    "    # separate out into input, drug and labels\n",
    "    train_source_inputs, val_source_inputs, test_source_inputs = train_source_data_merged[features2select], val_source_data_merged[features2select], test_source_data_merged[features2select]\n",
    "    # pass cl samples through cl diff model and vae\n",
    "    train_source_inputs_vae = pd.DataFrame(vae_decoder_input(train_source_inputs, cl_vae, cl_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"cl_vae_k_list\"][-1]//2)], index=train_source_data_merged.index)\n",
    "    val_source_inputs_vae = pd.DataFrame(vae_decoder_input(val_source_inputs, cl_vae, cl_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"cl_vae_k_list\"][-1]//2)], index=val_source_data_merged.index)\n",
    "    test_source_inputs_vae = pd.DataFrame(vae_decoder_input(test_source_inputs, cl_vae, cl_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"cl_vae_k_list\"][-1]//2)], index=test_source_data_merged.index)\n",
    "    train_source_drugs, val_source_drugs, test_source_drugs = train_source_data_merged[[str(i) for i in range(0, 2048)]].values, val_source_data_merged[[str(i) for i in range(0, 2048)]].values, test_source_data_merged[[str(i) for i in range(0, 2048)]].values\n",
    "    train_source_labels, val_source_labels, test_source_labels = train_source_data_merged[\"auc\"].values, val_source_data_merged[\"auc\"].values, test_source_data_merged[\"auc\"].values\n",
    "\n",
    "    train_target_inputs, val_target_inputs, test_target_inputs = train_target_data_merged[features2select], val_target_data_merged[features2select], test_target_data_merged[features2select]\n",
    "    # pass patient samples through tcga diff model and vae\n",
    "    train_target_inputs_vae = pd.DataFrame(vae_decoder_input(train_target_inputs, patient_vae, tcga_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"patient_vae_k_list\"][-1]//2)], index=train_target_data_merged.sample_id)\n",
    "    val_target_inputs_vae = pd.DataFrame(vae_decoder_input(val_target_inputs, patient_vae, tcga_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"patient_vae_k_list\"][-1]//2)], index=val_target_data_merged.sample_id)\n",
    "    test_target_inputs_vae = pd.DataFrame(vae_decoder_input(test_target_inputs, patient_vae, tcga_diff_model), columns=[f\"vae_feat{i}\" for i in range(model_config[\"patient_vae_k_list\"][-1]//2)], index=test_target_data_merged.sample_id)\n",
    "\n",
    "    train_target_drugs, val_target_drugs, test_target_drugs = train_target_data_merged[[str(i) for i in range(0, 2048)]].values, val_target_data_merged[[str(i) for i in range(0, 2048)]].values, test_target_data_merged[[str(i) for i in range(0, 2048)]].values\n",
    "    train_target_labels, val_target_labels, test_target_labels = train_target_data_merged[\"recist\"].values, val_target_data_merged[\"recist\"].values, test_target_data_merged[\"recist\"].values\n",
    "\n",
    "    return train_source_inputs_vae, train_source_drugs, train_source_labels, val_source_inputs_vae, val_source_drugs, val_source_labels, test_source_inputs_vae, test_source_drugs, test_source_labels, train_target_inputs_vae, train_target_drugs, train_target_labels, val_target_inputs_vae, val_target_drugs, val_target_labels, test_target_inputs_vae, test_target_drugs, test_target_labels, train_target_data_merged, val_target_data_merged, test_target_data_merged, train_source_data_merged, val_source_data_merged, test_source_data_merged\n",
    "\n",
    "    # pass # needs to return (train_source_data, train_source_labels, val_source_data, val_source_labels, test_source_data, test_source_labels), (train_target_data, train_target_labels, val_target_data, val_target_labels, test_target_data, test_target_labels)\n",
    "    #  Dummy data\n",
    "    # train_source_data, val_source_data, test_source_data = np.random.rand(32, 2048 + 4), np.random.rand(10, 2048 + 4), np.random.rand(5, 2048 + 4)\n",
    "    # train_source_labels, val_source_labels, test_source_labels = np.random.randint(2, size=32), np.random.randint(2, size=10), np.random.randint(2, size=5)\n",
    "    # train_target_data, val_target_data, test_target_data = np.random.rand(32, 2048 + 4), np.random.rand(10, 2048 + 4), np.random.rand(3, 2048 + 4)\n",
    "    # train_target_labels, val_target_labels, test_target_labels = np.random.randint(2, size=32), np.random.randint(2, size=10), np.random.randint(2, size=3)\n",
    "    # return train_source_data, train_source_labels, val_source_data, val_source_labels, test_source_data, test_source_labels, train_target_data, train_target_labels, val_target_data, val_target_labels, test_target_data, test_target_labels\n",
    "\n",
    "def load_augmented_cl_dataset(sample_id):\n",
    "    augmented_cl_df = pd.read_csv(f\"{pretrained_folder}/augmented_cl_clconditioned_uda_v2_vaeinput_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.csv\", index_col=0)\n",
    "    print(f\"Loaded augmented CL data: {augmented_cl_df.shape}\")\n",
    "    return augmented_cl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2db0bc9-b9eb-4cd1-adc7-ea92e0244aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: encoder \n",
      "Sequential(\n",
      "  (enc-0): Linear(in_features=797, out_features=512, bias=True)\n",
      "  (act-0): Tanh()\n",
      "  (enc-1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (act-1): ReLU()\n",
      ")\n",
      "#\n",
      "mu_layer: \n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "#\n",
      "sigma_layer: \n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "#\n",
      "U: decoder \n",
      "Sequential(\n",
      "  (-dec-0): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (-act-0): Tanh()\n",
      "  (dec-0): Linear(in_features=128, out_features=512, bias=True)\n",
      "  (act-0): Tanh()\n",
      "  (dec-1): Linear(in_features=512, out_features=797, bias=True)\n",
      "  (act-1): Sigmoid()\n",
      ")\n",
      "U: encoder \n",
      "Sequential(\n",
      "  (enc-0): Linear(in_features=797, out_features=1024, bias=True)\n",
      "  (act-0): Tanh()\n",
      "  (enc-1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (act-1): Tanh()\n",
      ")\n",
      "#\n",
      "mu_layer: \n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "#\n",
      "sigma_layer: \n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "#\n",
      "U: decoder \n",
      "Sequential(\n",
      "  (-dec-0): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (-act-0): Tanh()\n",
      "  (dec-0): Linear(in_features=128, out_features=1024, bias=True)\n",
      "  (act-0): Tanh()\n",
      "  (dec-1): Linear(in_features=1024, out_features=797, bias=True)\n",
      "  (act-1): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cl_diff_model, cl_vae, tcga_diff_model, patient_vae = load_pretrained_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d37ebec-6945-4f83-9c2d-ea08154ff733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: encoder \n",
      "Sequential(\n",
      "  (enc-0): Linear(in_features=797, out_features=512, bias=True)\n",
      "  (act-0): Tanh()\n",
      "  (enc-1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (act-1): ReLU()\n",
      ")\n",
      "#\n",
      "mu_layer: \n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "#\n",
      "sigma_layer: \n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "#\n",
      "U: decoder \n",
      "Sequential(\n",
      "  (-dec-0): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (-act-0): Tanh()\n",
      "  (dec-0): Linear(in_features=128, out_features=512, bias=True)\n",
      "  (act-0): Tanh()\n",
      "  (dec-1): Linear(in_features=512, out_features=797, bias=True)\n",
      "  (act-1): Sigmoid()\n",
      ")\n",
      "U: encoder \n",
      "Sequential(\n",
      "  (enc-0): Linear(in_features=797, out_features=1024, bias=True)\n",
      "  (act-0): Tanh()\n",
      "  (enc-1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (act-1): Tanh()\n",
      ")\n",
      "#\n",
      "mu_layer: \n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "#\n",
      "sigma_layer: \n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "#\n",
      "U: decoder \n",
      "Sequential(\n",
      "  (-dec-0): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (-act-0): Tanh()\n",
      "  (dec-0): Linear(in_features=128, out_features=1024, bias=True)\n",
      "  (act-0): Tanh()\n",
      "  (dec-1): Linear(in_features=1024, out_features=797, bias=True)\n",
      "  (act-1): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_source_inputs_vae, train_source_drugs, train_source_labels, val_source_inputs_vae, val_source_drugs, val_source_labels, test_source_inputs_vae, test_source_drugs, test_source_labels, train_target_inputs_vae, train_target_drugs, train_target_labels, val_target_inputs_vae, val_target_drugs, val_target_labels, test_target_inputs_vae, test_target_drugs, test_target_labels, train_target_data_merged, val_target_data_merged, test_target_data_merged, train_source_data_merged, val_source_data_merged, test_source_data_merged = load_datasets(sample_id=fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "365ff108-3007-49fc-9404-12b4cdbb03e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transformer_embedded_0</th>\n",
       "      <th>transformer_embedded_1</th>\n",
       "      <th>transformer_embedded_2</th>\n",
       "      <th>transformer_embedded_3</th>\n",
       "      <th>transformer_embedded_4</th>\n",
       "      <th>transformer_embedded_5</th>\n",
       "      <th>transformer_embedded_6</th>\n",
       "      <th>transformer_embedded_7</th>\n",
       "      <th>transformer_embedded_8</th>\n",
       "      <th>transformer_embedded_9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156436</th>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156437</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156438</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156439</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156440</th>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156441 rows × 2848 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        transformer_embedded_0  transformer_embedded_1  \\\n",
       "0                     0.000031               -0.000008   \n",
       "1                     0.000035                0.000021   \n",
       "2                     0.000010                0.000035   \n",
       "3                     0.000010                0.000026   \n",
       "4                     0.000025                0.000006   \n",
       "...                        ...                     ...   \n",
       "156436                0.000035                0.000006   \n",
       "156437                0.000021                0.000045   \n",
       "156438                0.000010                0.000035   \n",
       "156439                0.000024                0.000035   \n",
       "156440                0.000035                0.000026   \n",
       "\n",
       "        transformer_embedded_2  transformer_embedded_3  \\\n",
       "0                     0.000022                0.000049   \n",
       "1                     0.000010                0.000037   \n",
       "2                     0.000026                0.000008   \n",
       "3                     0.000003                0.000023   \n",
       "4                    -0.000016                0.000047   \n",
       "...                        ...                     ...   \n",
       "156436                0.000002                0.000030   \n",
       "156437                0.000008                0.000016   \n",
       "156438                0.000039                0.000011   \n",
       "156439                0.000046                0.000033   \n",
       "156440                0.000032                0.000022   \n",
       "\n",
       "        transformer_embedded_4  transformer_embedded_5  \\\n",
       "0                     0.000002                0.000032   \n",
       "1                     0.000002               -0.000016   \n",
       "2                     0.000032                0.000002   \n",
       "3                     0.000007                0.000021   \n",
       "4                     0.000020                0.000010   \n",
       "...                        ...                     ...   \n",
       "156436                0.000012                0.000031   \n",
       "156437                0.000011                0.000022   \n",
       "156438                0.000032                0.000035   \n",
       "156439                0.000024                0.000026   \n",
       "156440                0.000015                0.000002   \n",
       "\n",
       "        transformer_embedded_6  transformer_embedded_7  \\\n",
       "0                     0.000032                0.000025   \n",
       "1                    -0.000001                0.000030   \n",
       "2                     0.000018                0.000027   \n",
       "3                     0.000018                0.000034   \n",
       "4                     0.000020                0.000047   \n",
       "...                        ...                     ...   \n",
       "156436                0.000036                0.000023   \n",
       "156437                0.000019               -0.000004   \n",
       "156438                0.000024                0.000053   \n",
       "156439                0.000027                0.000031   \n",
       "156440                0.000027                0.000030   \n",
       "\n",
       "        transformer_embedded_8  transformer_embedded_9  ...  2038  2039  2040  \\\n",
       "0                     0.000010                0.000030  ...     0     0     0   \n",
       "1                     0.000013                0.000022  ...     0     0     0   \n",
       "2                     0.000017                0.000007  ...     0     0     0   \n",
       "3                     0.000015                0.000018  ...     0     0     0   \n",
       "4                     0.000035                0.000031  ...     0     0     0   \n",
       "...                        ...                     ...  ...   ...   ...   ...   \n",
       "156436                0.000031                0.000031  ...     0     0     0   \n",
       "156437                0.000031                0.000031  ...     0     0     0   \n",
       "156438                0.000031                0.000031  ...     0     0     0   \n",
       "156439                0.000031                0.000031  ...     0     0     0   \n",
       "156440                0.000036                0.000059  ...     0     0     0   \n",
       "\n",
       "        2041  2042  2043  2044  2045  2046  2047  \n",
       "0          0     0     0     0     0     0     0  \n",
       "1          0     0     0     0     0     0     0  \n",
       "2          0     0     0     0     0     0     0  \n",
       "3          0     0     0     0     0     0     0  \n",
       "4          0     0     0     0     0     0     0  \n",
       "...      ...   ...   ...   ...   ...   ...   ...  \n",
       "156436     0     0     0     0     0     0     0  \n",
       "156437     0     0     0     0     0     0     0  \n",
       "156438     0     0     0     0     0     0     0  \n",
       "156439     0     0     0     0     0     0     0  \n",
       "156440     0     0     0     0     0     0     0  \n",
       "\n",
       "[156441 rows x 2848 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_source_data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2935b5a-e494-46c0-82a5-ff0a1cc7910b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>drug_name</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>DOCETAXEL</td>\n",
       "      <td>0.191876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PR-L3QLdq</td>\n",
       "      <td>ELEPHANTIN</td>\n",
       "      <td>0.940458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PR-NxSV8u</td>\n",
       "      <td>MITOXANTRONE</td>\n",
       "      <td>0.921925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PR-oLPbwB</td>\n",
       "      <td>DACTINOMYCIN</td>\n",
       "      <td>0.179515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR-4ngqZx</td>\n",
       "      <td>CCT007093</td>\n",
       "      <td>0.989986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156436</th>\n",
       "      <td>PR-M4505H</td>\n",
       "      <td>PFI-1</td>\n",
       "      <td>0.919051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156437</th>\n",
       "      <td>PR-Bz57NU</td>\n",
       "      <td>NILOTINIB</td>\n",
       "      <td>0.995489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156438</th>\n",
       "      <td>PR-6SyWYo</td>\n",
       "      <td>SAPITINIB</td>\n",
       "      <td>0.492491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156439</th>\n",
       "      <td>PR-wGySam</td>\n",
       "      <td>TASELISIB</td>\n",
       "      <td>0.901939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156440</th>\n",
       "      <td>PR-8kT9dj</td>\n",
       "      <td>PICTILISIB</td>\n",
       "      <td>0.866490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156441 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample_id     drug_name       auc\n",
       "0       PR-132fPs     DOCETAXEL  0.191876\n",
       "1       PR-L3QLdq    ELEPHANTIN  0.940458\n",
       "2       PR-NxSV8u  MITOXANTRONE  0.921925\n",
       "3       PR-oLPbwB  DACTINOMYCIN  0.179515\n",
       "4       PR-4ngqZx     CCT007093  0.989986\n",
       "...           ...           ...       ...\n",
       "156436  PR-M4505H         PFI-1  0.919051\n",
       "156437  PR-Bz57NU     NILOTINIB  0.995489\n",
       "156438  PR-6SyWYo     SAPITINIB  0.492491\n",
       "156439  PR-wGySam     TASELISIB  0.901939\n",
       "156440  PR-8kT9dj    PICTILISIB  0.866490\n",
       "\n",
       "[156441 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_source_data_merged[[\"sample_id\", \"drug_name\", \"auc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41ad38c3-1b28-416a-ab7f-94eb548683f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transformer_embedded_0</th>\n",
       "      <th>transformer_embedded_1</th>\n",
       "      <th>transformer_embedded_2</th>\n",
       "      <th>transformer_embedded_3</th>\n",
       "      <th>transformer_embedded_4</th>\n",
       "      <th>transformer_embedded_5</th>\n",
       "      <th>transformer_embedded_6</th>\n",
       "      <th>transformer_embedded_7</th>\n",
       "      <th>transformer_embedded_8</th>\n",
       "      <th>transformer_embedded_9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 2850 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     transformer_embedded_0  transformer_embedded_1  transformer_embedded_2  \\\n",
       "0                  0.000042                0.000027                0.000044   \n",
       "1                  0.000035                0.000042                0.000039   \n",
       "2                  0.000042                0.000028                0.000031   \n",
       "3                  0.000034                0.000040                0.000051   \n",
       "4                  0.000032                0.000052                0.000042   \n",
       "..                      ...                     ...                     ...   \n",
       "483                0.000042                0.000057                0.000040   \n",
       "484                0.000029                0.000019                0.000041   \n",
       "485                0.000030                0.000042                0.000052   \n",
       "486                0.000037                0.000042                0.000018   \n",
       "487                0.000048                0.000038                0.000016   \n",
       "\n",
       "     transformer_embedded_3  transformer_embedded_4  transformer_embedded_5  \\\n",
       "0                  0.000045                0.000026                0.000034   \n",
       "1                  0.000006                0.000054                0.000042   \n",
       "2                  0.000029                0.000038                0.000037   \n",
       "3                  0.000045                0.000039                0.000042   \n",
       "4                  0.000042                0.000042                0.000042   \n",
       "..                      ...                     ...                     ...   \n",
       "483                0.000026                0.000042                0.000042   \n",
       "484                0.000041                0.000037                0.000047   \n",
       "485                0.000026                0.000027                0.000025   \n",
       "486                0.000038                0.000037                0.000042   \n",
       "487                0.000038                0.000049                0.000040   \n",
       "\n",
       "     transformer_embedded_6  transformer_embedded_7  transformer_embedded_8  \\\n",
       "0                  0.000034                0.000048                0.000041   \n",
       "1                  0.000042                0.000042                0.000042   \n",
       "2                  0.000025                0.000047                0.000042   \n",
       "3                  0.000042                0.000042                0.000042   \n",
       "4                  0.000042                0.000042                0.000042   \n",
       "..                      ...                     ...                     ...   \n",
       "483                0.000042                0.000042                0.000042   \n",
       "484                0.000042                0.000049                0.000026   \n",
       "485                0.000042                0.000042                0.000042   \n",
       "486                0.000042                0.000042                0.000042   \n",
       "487                0.000038                0.000027                0.000039   \n",
       "\n",
       "     transformer_embedded_9  ...  2038  2039  2040  2041  2042  2043  2044  \\\n",
       "0                  0.000029  ...     0     0     0     0     1     0     0   \n",
       "1                  0.000042  ...     0     0     0     0     0     0     0   \n",
       "2                  0.000042  ...     0     0     0     0     0     0     0   \n",
       "3                  0.000042  ...     0     0     0     0     0     0     0   \n",
       "4                  0.000042  ...     0     0     0     0     0     0     0   \n",
       "..                      ...  ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "483                0.000042  ...     0     0     0     0     0     0     0   \n",
       "484                0.000028  ...     0     0     0     0     0     0     0   \n",
       "485                0.000042  ...     0     0     0     0     0     0     0   \n",
       "486                0.000042  ...     0     0     0     0     0     1     0   \n",
       "487                0.000042  ...     0     0     0     0     0     0     0   \n",
       "\n",
       "     2045  2046  2047  \n",
       "0       0     0     0  \n",
       "1       0     0     0  \n",
       "2       0     0     0  \n",
       "3       0     0     0  \n",
       "4       0     0     0  \n",
       "..    ...   ...   ...  \n",
       "483     0     0     0  \n",
       "484     0     0     0  \n",
       "485     0     0     0  \n",
       "486     0     0     0  \n",
       "487     0     0     0  \n",
       "\n",
       "[488 rows x 2850 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b53300c9-3437-4cf7-9964-00c5afad4a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transformer_embedded_0</th>\n",
       "      <th>transformer_embedded_1</th>\n",
       "      <th>transformer_embedded_2</th>\n",
       "      <th>transformer_embedded_3</th>\n",
       "      <th>transformer_embedded_4</th>\n",
       "      <th>transformer_embedded_5</th>\n",
       "      <th>transformer_embedded_6</th>\n",
       "      <th>transformer_embedded_7</th>\n",
       "      <th>transformer_embedded_8</th>\n",
       "      <th>transformer_embedded_9</th>\n",
       "      <th>...</th>\n",
       "      <th>transformer_embedded_787</th>\n",
       "      <th>transformer_embedded_788</th>\n",
       "      <th>transformer_embedded_789</th>\n",
       "      <th>transformer_embedded_790</th>\n",
       "      <th>transformer_embedded_791</th>\n",
       "      <th>transformer_embedded_792</th>\n",
       "      <th>transformer_embedded_793</th>\n",
       "      <th>transformer_embedded_794</th>\n",
       "      <th>transformer_embedded_795</th>\n",
       "      <th>transformer_embedded_796</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 797 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     transformer_embedded_0  transformer_embedded_1  transformer_embedded_2  \\\n",
       "0                  0.000042                0.000027                0.000044   \n",
       "1                  0.000035                0.000042                0.000039   \n",
       "2                  0.000042                0.000028                0.000031   \n",
       "3                  0.000034                0.000040                0.000051   \n",
       "4                  0.000032                0.000052                0.000042   \n",
       "..                      ...                     ...                     ...   \n",
       "483                0.000042                0.000057                0.000040   \n",
       "484                0.000029                0.000019                0.000041   \n",
       "485                0.000030                0.000042                0.000052   \n",
       "486                0.000037                0.000042                0.000018   \n",
       "487                0.000048                0.000038                0.000016   \n",
       "\n",
       "     transformer_embedded_3  transformer_embedded_4  transformer_embedded_5  \\\n",
       "0                  0.000045                0.000026                0.000034   \n",
       "1                  0.000006                0.000054                0.000042   \n",
       "2                  0.000029                0.000038                0.000037   \n",
       "3                  0.000045                0.000039                0.000042   \n",
       "4                  0.000042                0.000042                0.000042   \n",
       "..                      ...                     ...                     ...   \n",
       "483                0.000026                0.000042                0.000042   \n",
       "484                0.000041                0.000037                0.000047   \n",
       "485                0.000026                0.000027                0.000025   \n",
       "486                0.000038                0.000037                0.000042   \n",
       "487                0.000038                0.000049                0.000040   \n",
       "\n",
       "     transformer_embedded_6  transformer_embedded_7  transformer_embedded_8  \\\n",
       "0                  0.000034                0.000048                0.000041   \n",
       "1                  0.000042                0.000042                0.000042   \n",
       "2                  0.000025                0.000047                0.000042   \n",
       "3                  0.000042                0.000042                0.000042   \n",
       "4                  0.000042                0.000042                0.000042   \n",
       "..                      ...                     ...                     ...   \n",
       "483                0.000042                0.000042                0.000042   \n",
       "484                0.000042                0.000049                0.000026   \n",
       "485                0.000042                0.000042                0.000042   \n",
       "486                0.000042                0.000042                0.000042   \n",
       "487                0.000038                0.000027                0.000039   \n",
       "\n",
       "     transformer_embedded_9  ...  transformer_embedded_787  \\\n",
       "0                  0.000029  ...                  0.000049   \n",
       "1                  0.000042  ...                  0.000050   \n",
       "2                  0.000042  ...                  0.000050   \n",
       "3                  0.000042  ...                  0.000050   \n",
       "4                  0.000042  ...                  0.000050   \n",
       "..                      ...  ...                       ...   \n",
       "483                0.000042  ...                  0.000050   \n",
       "484                0.000028  ...                  0.000048   \n",
       "485                0.000042  ...                  0.000050   \n",
       "486                0.000042  ...                  0.000050   \n",
       "487                0.000042  ...                  0.000050   \n",
       "\n",
       "     transformer_embedded_788  transformer_embedded_789  \\\n",
       "0                    0.000049                  0.000049   \n",
       "1                    0.000050                  0.000050   \n",
       "2                    0.000050                  0.000050   \n",
       "3                    0.000050                  0.000050   \n",
       "4                    0.000050                  0.000050   \n",
       "..                        ...                       ...   \n",
       "483                  0.000050                  0.000050   \n",
       "484                  0.000048                  0.000048   \n",
       "485                  0.000050                  0.000050   \n",
       "486                  0.000050                  0.000050   \n",
       "487                  0.000050                  0.000050   \n",
       "\n",
       "     transformer_embedded_790  transformer_embedded_791  \\\n",
       "0                    0.000049                  0.000049   \n",
       "1                    0.000050                  0.000050   \n",
       "2                    0.000050                  0.000050   \n",
       "3                    0.000050                  0.000050   \n",
       "4                    0.000050                  0.000050   \n",
       "..                        ...                       ...   \n",
       "483                  0.000050                  0.000050   \n",
       "484                  0.000048                  0.000048   \n",
       "485                  0.000050                  0.000050   \n",
       "486                  0.000050                  0.000050   \n",
       "487                  0.000050                  0.000050   \n",
       "\n",
       "     transformer_embedded_792  transformer_embedded_793  \\\n",
       "0                    0.000049                  0.000049   \n",
       "1                    0.000050                  0.000050   \n",
       "2                    0.000050                  0.000050   \n",
       "3                    0.000050                  0.000050   \n",
       "4                    0.000050                  0.000050   \n",
       "..                        ...                       ...   \n",
       "483                  0.000050                  0.000050   \n",
       "484                  0.000048                  0.000048   \n",
       "485                  0.000050                  0.000050   \n",
       "486                  0.000050                  0.000050   \n",
       "487                  0.000050                  0.000050   \n",
       "\n",
       "     transformer_embedded_794  transformer_embedded_795  \\\n",
       "0                    0.000049                  0.000049   \n",
       "1                    0.000050                  0.000050   \n",
       "2                    0.000050                  0.000050   \n",
       "3                    0.000050                  0.000050   \n",
       "4                    0.000050                  0.000050   \n",
       "..                        ...                       ...   \n",
       "483                  0.000050                  0.000050   \n",
       "484                  0.000048                  0.000048   \n",
       "485                  0.000050                  0.000050   \n",
       "486                  0.000050                  0.000050   \n",
       "487                  0.000050                  0.000050   \n",
       "\n",
       "     transformer_embedded_796  \n",
       "0                    0.000049  \n",
       "1                    0.000050  \n",
       "2                    0.000050  \n",
       "3                    0.000050  \n",
       "4                    0.000050  \n",
       "..                        ...  \n",
       "483                  0.000050  \n",
       "484                  0.000048  \n",
       "485                  0.000050  \n",
       "486                  0.000050  \n",
       "487                  0.000050  \n",
       "\n",
       "[488 rows x 797 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_data_merged.filter(regex=\"transformer_embedded_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f699e022-32a2-47f7-95d7-0a5fd4da9017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>drug_name</th>\n",
       "      <th>recist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-FD-A6TC</td>\n",
       "      <td>GEMCITABINE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-S9-A6TS</td>\n",
       "      <td>CARMUSTINE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-VR-A8EQ</td>\n",
       "      <td>FLUOROURACIL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_DS_bkm_034_T</td>\n",
       "      <td>BUPARLISIB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-YU-A90Q</td>\n",
       "      <td>CARBOPLATIN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>s_DS_bkm_013_T</td>\n",
       "      <td>BUPARLISIB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>TCGA-GN-A8LK</td>\n",
       "      <td>CARBOPLATIN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>TCGA-VS-A8EJ</td>\n",
       "      <td>CISPLATIN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>P-0021780-T01-IM6</td>\n",
       "      <td>SORAFENIB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>TCGA-VS-A8EK</td>\n",
       "      <td>CISPLATIN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sample_id     drug_name  recist\n",
       "0         TCGA-FD-A6TC   GEMCITABINE       1\n",
       "1         TCGA-S9-A6TS    CARMUSTINE       0\n",
       "2         TCGA-VR-A8EQ  FLUOROURACIL       1\n",
       "3       s_DS_bkm_034_T    BUPARLISIB       0\n",
       "4         TCGA-YU-A90Q   CARBOPLATIN       1\n",
       "..                 ...           ...     ...\n",
       "483     s_DS_bkm_013_T    BUPARLISIB       0\n",
       "484       TCGA-GN-A8LK   CARBOPLATIN       0\n",
       "485       TCGA-VS-A8EJ     CISPLATIN       0\n",
       "486  P-0021780-T01-IM6     SORAFENIB       0\n",
       "487       TCGA-VS-A8EK     CISPLATIN       1\n",
       "\n",
       "[488 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_data_merged[[\"sample_id\", \"drug_name\", \"recist\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d3524e4-658f-4b3d-9c03-db60dad57819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "# Cell Lines\n",
    "source_dataset_train = TensorDataset(torch.FloatTensor(train_source_data_merged.filter(regex=\"transformer_embedded_*\").values), torch.FloatTensor(train_source_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(train_source_data_merged[\"auc\"].values))\n",
    "source_dataset_val = TensorDataset(torch.FloatTensor(val_source_data_merged.filter(regex=\"transformer_embedded_*\").values), torch.FloatTensor(val_source_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(val_source_data_merged[\"auc\"].values))\n",
    "source_dataset_test = TensorDataset(torch.FloatTensor(test_source_data_merged.filter(regex=\"transformer_embedded_*\").values), torch.FloatTensor(test_source_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(test_source_data_merged[\"auc\"].values))\n",
    "\n",
    "# Patients\n",
    "target_dataset_train = TensorDataset(torch.FloatTensor(train_target_data_merged.filter(regex=\"transformer_embedded_*\").values), torch.FloatTensor(train_target_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(train_target_data_merged[\"recist\"].values))\n",
    "target_dataset_val = TensorDataset(torch.FloatTensor(val_target_data_merged.filter(regex=\"transformer_embedded_*\").values), torch.FloatTensor(val_target_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(val_target_data_merged[\"recist\"].values))\n",
    "target_dataset_test = TensorDataset(torch.FloatTensor(test_target_data_merged.filter(regex=\"transformer_embedded_*\").values), torch.FloatTensor(test_target_data_merged[[str(i) for i in range(0, 2048)]].values), torch.FloatTensor(test_target_data_merged[\"recist\"].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6116eae-ff0c-4bc0-a2a9-c6a4dfc79b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loaders\n",
    "source_dataloader_train = DataLoader(source_dataset_train, batch_size = 512, shuffle = True, worker_init_fn = seed_worker, generator = g)\n",
    "target_dataloader_train = DataLoader(target_dataset_train, batch_size = 512, shuffle = True, worker_init_fn = seed_worker, generator = g)\n",
    "\n",
    "source_dataloader_val = DataLoader(source_dataset_val, batch_size = 512, shuffle = False, worker_init_fn = seed_worker, generator = g)\n",
    "target_dataloader_val = DataLoader(target_dataset_val, batch_size = 512, shuffle = False, worker_init_fn = seed_worker, generator = g)\n",
    "\n",
    "source_dataloader_test = DataLoader(source_dataset_test, batch_size = 512, shuffle = False, worker_init_fn = seed_worker, generator = g)\n",
    "target_dataloader_test = DataLoader(target_dataset_test, batch_size = 512, shuffle = False, worker_init_fn = seed_worker, generator = g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67665274-c235-43e2-9840-631186c8c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STL(nn.Module):\n",
    "    def __init__(self, cl_vae, patient_vae):\n",
    "        super().__init__()\n",
    "        # self.cl_vae = cl_vae\n",
    "        self.patient_vae = patient_vae\n",
    "        self.drug_embedder = nn.Sequential(nn.Linear(2048, 256), nn.ReLU(), nn.Linear(256, 64))\n",
    "        # self.audrc_predictor = nn.Sequential(nn.Linear(64 * 2, 16), nn.ReLU(), nn.Linear(16, 1))\n",
    "        self.recist_predictor = nn.Sequential(nn.Linear(64 * 2, 16), nn.ReLU(), nn.Linear(16, 1))\n",
    "\n",
    "    def forward(self, cl_inp, cl_drug, patient_inp, patient_drug, audrc, recist):\n",
    "        # cl_inp and patient_inp are 797 dim, both drugs are 2048 dim\n",
    "        # cl_inp_emb, _, _, _ = self.cl_vae(cl_inp) # From VAE encoder + reparameterization\n",
    "        patient_inp_emb, _, _, _ = self.patient_vae(patient_inp)\n",
    "\n",
    "        # cl_drug_emb = self.drug_embedder(cl_drug)\n",
    "        patient_drug_emb = self.drug_embedder(patient_drug)\n",
    "\n",
    "        # cl_cat = torch.cat((cl_inp_emb, cl_drug_emb), axis = 1)\n",
    "        patient_cat = torch.cat((patient_inp_emb, patient_drug_emb), axis = 1)\n",
    "\n",
    "        # recist and audrc prediction\n",
    "        # audrc_pred = self.audrc_predictor(cl_cat)\n",
    "        recist_pred = self.recist_predictor(patient_cat)\n",
    "\n",
    "        return patient_cat, recist_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9422337-1db4-424f-bf24-1867699f5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train STL\n",
    "mtl_model = STL(cl_vae, patient_vae).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b57d1fde-2df6-4996-9e97-649c88adf9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = mtl_model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e03fe9f9-17df-4ad3-bf86-01f92455d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_loop(model, cl_val_loader, patient_val_loader):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    true = []\n",
    "    for idx, batch in enumerate(patient_val_loader):\n",
    "        patient_inp = batch[0].to(device)\n",
    "        drug_inp = batch[1].to(device)\n",
    "        label = batch[2].to(device)\n",
    "        with torch.no_grad():\n",
    "            patient_emb, _, _, _ = model.patient_vae(patient_inp)\n",
    "            drug_emb = model.drug_embedder(drug_inp)\n",
    "            patient_cat = torch.cat((patient_emb, drug_emb), axis = 1)\n",
    "            pred = model.recist_predictor(patient_cat)\n",
    "            prediction.append(pred)\n",
    "            true.append(label)\n",
    "    predictions = torch.cat(prediction).view(-1, 1)\n",
    "    trues = torch.cat(true).view(-1, 1)\n",
    "    return nn.BCEWithLogitsLoss()(predictions, trues)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c00b81d6-8764-40e8-9ac3-625506b679a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss = 0.6905865229033177, val patient loss = 0.6807147860527039\n",
      "Best val loss = 0.6807147860527039\n",
      "Current val loss = 0.6807147860527039\n",
      "Saved!\n",
      "Epoch 1: train loss = 0.6261450737909554, val patient loss = 0.6468987464904785\n",
      "Best val loss = 0.6807147860527039\n",
      "Current val loss = 0.6468987464904785\n",
      "Saved!\n",
      "Epoch 2: train loss = 0.5423766359005099, val patient loss = 0.6651303172111511\n",
      "Best val loss = 0.6468987464904785\n",
      "Current val loss = 0.6651303172111511\n",
      "Increased count\n",
      "Epoch 3: train loss = 0.5062332820463804, val patient loss = 0.657333493232727\n",
      "Best val loss = 0.6468987464904785\n",
      "Current val loss = 0.657333493232727\n",
      "Increased count\n",
      "Epoch 4: train loss = 0.49207860426185956, val patient loss = 0.6624070405960083\n",
      "Best val loss = 0.6468987464904785\n",
      "Current val loss = 0.6624070405960083\n",
      "Increased count\n",
      "Converged\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "count = 0\n",
    "patient_val_losses = []\n",
    "for epoch in range(300):\n",
    "    mtl_model.train()\n",
    "    epoch_loss = []\n",
    "    for idx0, batch0 in enumerate(source_dataloader_train):\n",
    "        for idx1, batch1 in enumerate(target_dataloader_train):\n",
    "            optimizer.zero_grad()\n",
    "            cl_inp, cl_drug, patient_inp, patient_drug, audrc, recist = batch0[0].to(device), batch0[1].to(device), batch1[0].to(device), batch1[1].to(device), batch0[2].to(device), batch1[2].to(device)\n",
    "            patient_cat, recist_pred = mtl_model(cl_inp, cl_drug, patient_inp, patient_drug, audrc, recist)\n",
    "\n",
    "            # # align both\n",
    "            # coral_loss = coral(cl_cat, patient_cat)\n",
    "\n",
    "            # losses\n",
    "            # audrc_loss = nn.MSELoss()(audrc_pred.view(-1, 1), audrc.view(-1, 1))\n",
    "            recist_loss = nn.BCEWithLogitsLoss()(recist_pred.view(-1, 1), recist.view(-1, 1))\n",
    "\n",
    "            # total_loss = coral_loss + audrc_loss + recist_loss\n",
    "            # total_loss = audrc_loss + recist_loss\n",
    "            total_loss = recist_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss.append(total_loss.cpu().detach().numpy().item())\n",
    "\n",
    "    # get val loss\n",
    "    patient_val_loss = testing_loop(mtl_model, source_dataloader_val, target_dataloader_val)\n",
    "    patient_val_losses.append(patient_val_loss.item())\n",
    "    print(f\"Epoch {epoch}: train loss = {np.mean(epoch_loss)}, val patient loss = {patient_val_loss.item()}\")\n",
    "\n",
    "    if len(patient_val_losses) ==  1:\n",
    "        best_val_loss = patient_val_loss.item()\n",
    "\n",
    "    print(f\"Best val loss = {best_val_loss}\")\n",
    "    print(f\"Current val loss = {patient_val_loss.item()}\")\n",
    "\n",
    "    if patient_val_loss.item() <= best_val_loss: # minimize val loss\n",
    "        torch.save(mtl_model.state_dict(), f\"{folder_config['model_checkpoint_folder']}MTL_model_fold{fold}.pth\")\n",
    "        best_val_loss = patient_val_loss\n",
    "        print(\"Saved!\")\n",
    "        count = 0\n",
    "    else:\n",
    "        print(\"Increased count\")\n",
    "        count += 1\n",
    "\n",
    "    if count >= 3:\n",
    "        print(\"Converged\")\n",
    "        break\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c923bc63-018b-4f01-8527-be5582ca92e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference on cell line, drug pairs to get pseudolabels\n",
    "mtl_model_trained = STL(cl_vae, patient_vae).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab14b26c-f38d-46f0-912c-368154b76ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model_trained.load_state_dict(torch.load(f\"{folder_config['model_checkpoint_folder']}MTL_model_fold{fold}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "872518f4-b050-4f69-8711-53a4983b7caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STL(\n",
       "  (patient_vae): vae(\n",
       "    (mu_layer): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (sigma_layer): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (encoder): Sequential(\n",
       "      (enc-0): Linear(in_features=797, out_features=512, bias=True)\n",
       "      (act-0): Tanh()\n",
       "      (enc-1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (act-1): ReLU()\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (-dec-0): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (-act-0): Tanh()\n",
       "      (dec-0): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (act-0): Tanh()\n",
       "      (dec-1): Linear(in_features=512, out_features=797, bias=True)\n",
       "      (act-1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (drug_embedder): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (recist_predictor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "440e8ed7-bada-486f-b9a1-4461d83502ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded augmented CL data: (1193, 64)\n"
     ]
    }
   ],
   "source": [
    "# Load augmented cell lines and drug combos\n",
    "cl_augmented_df = load_augmented_cl_dataset(model_config[\"sample_id\"])\n",
    "train_val_cell_lines = list(cl_augmented_df.index)\n",
    "if model_config[\"experiment_id\"] == \"1B\":\n",
    "    drugs_with_fp = [model_config[\"experiment_settings\"].split(\", \")[0]] # extract out drug name\n",
    "elif model_config[\"experiment_id\"] == \"1A\":\n",
    "    drugs_with_fp = [model_config[\"experiment_settings\"]] # has only drug name\n",
    "else: # in 2A and 2B include all available drugs with fp\n",
    "    drugs_with_fp = list(drug_fp.index)\n",
    "possible_cl_drug_combinations = list(itertools.product(train_val_cell_lines, drugs_with_fp))\n",
    "possible_cl_drug_combinations_df = pd.DataFrame(possible_cl_drug_combinations, columns = [\"sample_id\", \"drug_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bef79039-e612-4a84-bbab-ecf5aa77a935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571447"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(possible_cl_drug_combinations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c372d539-d084-41e1-98d9-196959f24a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using data loaders to prevent execessive memory usage\n",
    "class CustomCellLineDataSetUnlabelled(TensorDataset):\n",
    "    def __init__(self, cl_augmented_df, drug_fp, possible_combinations): # possible_combinations must only consist of samples with drug name with a fingerprint\n",
    "        self.possible_combinations = possible_combinations\n",
    "        self.augmented_cl_df = cl_augmented_df\n",
    "        self.drug_fp = drug_fp\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_name, drug_name = self.possible_combinations[idx]\n",
    "        mut_profile = self.augmented_cl_df.loc[sample_name].values\n",
    "        drug_inp = self.drug_fp.loc[drug_name].values\n",
    "        return torch.FloatTensor(mut_profile), torch.FloatTensor(drug_inp)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.possible_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bc93e04-7a0a-4e9f-a340-4139b5f58fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible cl drug combos before pseudo label based filtering: \n",
      "571447\n"
     ]
    }
   ],
   "source": [
    "cl_aug_train_dataset = CustomCellLineDataSetUnlabelled(cl_augmented_df, drug_fp, possible_cl_drug_combinations)\n",
    "print(\"Number of possible cl drug combos before pseudo label based filtering: \")\n",
    "print(len(cl_aug_train_dataset))\n",
    "cl_aug_train_dataloader = DataLoader(cl_aug_train_dataset, batch_size=model_config[\"source_batch_size\"], shuffle=False) # to preserve order for later subset selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96040547-0805-4ae0-b96f-8605b3df00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_mtl(model, cl_aug_train_dataloader):\n",
    "    # forward on augmented cl data, via the patient embedder, and recist predictor\n",
    "    model.eval()\n",
    "    pseudo_y = []\n",
    "    for idx, batch in enumerate(cl_aug_train_dataloader):\n",
    "        patient_inp_emb = batch[0].to(device)\n",
    "        patient_drug = batch[1].to(device)\n",
    "        # print(patient_inp.shape)\n",
    "        with torch.no_grad():\n",
    "            # patient_inp_emb, _, _, _ = model.patient_vae(patient_inp)\n",
    "        \n",
    "            patient_drug_emb = model.drug_embedder(patient_drug)\n",
    "        \n",
    "            patient_cat = torch.cat((patient_inp_emb, patient_drug_emb), axis = 1)\n",
    "        \n",
    "            recist_pred = nn.Sigmoid()(model.recist_predictor(patient_cat)).view(-1, 1)\n",
    "            pseudo_y.append(recist_pred)\n",
    "\n",
    "    return torch.cat(pseudo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08561368-85f9-49d3-a30c-560ea7e09d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>drug_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>KIN001-260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>NSC-87877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>GNE-317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>NAVITOCLAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571442</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>SB590885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571443</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>STAUROSPORINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571444</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>TW 37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571445</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>ULIXERTINIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571446</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>ZM447439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>571447 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample_id      drug_name\n",
       "0       PR-132fPs      JW-7-24-1\n",
       "1       PR-132fPs     KIN001-260\n",
       "2       PR-132fPs      NSC-87877\n",
       "3       PR-132fPs        GNE-317\n",
       "4       PR-132fPs     NAVITOCLAX\n",
       "...           ...            ...\n",
       "571442  PR-2AxAKM       SB590885\n",
       "571443  PR-2AxAKM  STAUROSPORINE\n",
       "571444  PR-2AxAKM          TW 37\n",
       "571445  PR-2AxAKM    ULIXERTINIB\n",
       "571446  PR-2AxAKM       ZM447439\n",
       "\n",
       "[571447 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels_df = pd.DataFrame()\n",
    "pseudolabels_df[[\"sample_id\", \"drug_name\"]] = possible_cl_drug_combinations\n",
    "pseudolabels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d381395a-ee54-40b8-aede-e0e4ca96534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pseudo labels\n",
    "pseudolabels = inference_mtl(mtl_model_trained, cl_aug_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cebb0eb-e38b-47f1-8a17-6cf62c821b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudolabels_df[\"pseudolabels\"] = pseudolabels.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fc82a86-9881-4729-b99e-38f7a2b90250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>drug_name</th>\n",
       "      <th>pseudolabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>JW-7-24-1</td>\n",
       "      <td>0.283367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>KIN001-260</td>\n",
       "      <td>0.334226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>NSC-87877</td>\n",
       "      <td>0.333292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>GNE-317</td>\n",
       "      <td>0.322697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR-132fPs</td>\n",
       "      <td>NAVITOCLAX</td>\n",
       "      <td>0.237425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571442</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>SB590885</td>\n",
       "      <td>0.443682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571443</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>STAUROSPORINE</td>\n",
       "      <td>0.417249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571444</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>TW 37</td>\n",
       "      <td>0.396079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571445</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>ULIXERTINIB</td>\n",
       "      <td>0.418779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571446</th>\n",
       "      <td>PR-2AxAKM</td>\n",
       "      <td>ZM447439</td>\n",
       "      <td>0.343693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>571447 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample_id      drug_name  pseudolabels\n",
       "0       PR-132fPs      JW-7-24-1      0.283367\n",
       "1       PR-132fPs     KIN001-260      0.334226\n",
       "2       PR-132fPs      NSC-87877      0.333292\n",
       "3       PR-132fPs        GNE-317      0.322697\n",
       "4       PR-132fPs     NAVITOCLAX      0.237425\n",
       "...           ...            ...           ...\n",
       "571442  PR-2AxAKM       SB590885      0.443682\n",
       "571443  PR-2AxAKM  STAUROSPORINE      0.417249\n",
       "571444  PR-2AxAKM          TW 37      0.396079\n",
       "571445  PR-2AxAKM    ULIXERTINIB      0.418779\n",
       "571446  PR-2AxAKM       ZM447439      0.343693\n",
       "\n",
       "[571447 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddcd2664-2855-40d5-9e70-c3967a9ba52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudolabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>571447.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.360678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.044616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.297697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.356581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.418189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.786013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pseudolabels\n",
       "count  571447.000000\n",
       "mean        0.360678\n",
       "std         0.090453\n",
       "min         0.044616\n",
       "25%         0.297697\n",
       "50%         0.356581\n",
       "75%         0.418189\n",
       "max         0.786013"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1db77148-fddb-418d-82e6-d2ece8b84267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary(prediction, lower_threshold, upper_threshold):\n",
    "    if prediction >= upper_threshold:\n",
    "        return 1\n",
    "    elif prediction < lower_threshold:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1379f84-b423-44cc-a433-4138d400866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold and select confident samples\n",
    "if fold in [0, 1]:\n",
    "    pseudolabels_df[\"pseudolabels_binary\"] = pseudolabels_df[\"pseudolabels\"].apply(lambda x: convert_binary(x, 0.1, 0.7))\n",
    "else:\n",
    "    pseudolabels_df[\"pseudolabels_binary\"] = pseudolabels_df[\"pseudolabels\"].apply(lambda x: convert_binary(x, 0.1, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d2f79f7-4dd0-4b84-8118-003069194ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pseudolabels_binary\n",
       "0    179\n",
       "1    129\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels_df[pseudolabels_df.pseudolabels_binary != -1][\"pseudolabels_binary\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d6d04f1-c292-499d-81ec-94259f8e5a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using data loaders to prevent execessive memory usage\n",
    "class CustomCombinedDataSetLabelled(TensorDataset):\n",
    "    def __init__(self, combined_df, cl_augmented_df, train_target_inputs_vae, drug_fp): # possible_combinations must only consist of samples with drug name with a fingerprint\n",
    "        self.sample_df = combined_df.reset_index(drop=True)\n",
    "        self.augmented_cl_df = cl_augmented_df\n",
    "        self.tcga_vae_df = train_target_inputs_vae[~train_target_inputs_vae.index.duplicated(keep=\"first\")]\n",
    "        self.drug_fp = drug_fp\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.sample_df.iloc[idx]\n",
    "        sample_name = row[\"sample_id\"]\n",
    "        drug_name = row[\"drug_name\"]\n",
    "        if sample_name in self.tcga_vae_df.index: # using VAE version instead of mutation profiles\n",
    "            mut_profile = self.tcga_vae_df.loc[sample_name].values\n",
    "        if sample_name in self.augmented_cl_df.index:\n",
    "            mut_profile = self.augmented_cl_df.loc[sample_name].values\n",
    "        drug_inp = self.drug_fp.loc[drug_name].values\n",
    "        response = row[\"recist\"]\n",
    "        return torch.FloatTensor(mut_profile), torch.FloatTensor(drug_inp), response\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a969eac-02ec-4ed3-8946-1807b867f0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of confident cl drug combinations with pseudolabels: \n",
      "(308, 3)\n",
      "Pseudo label distribution after majority vote:\n",
      "recist\n",
      "0    179\n",
      "1    129\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# non-abstained, confident pseudo labels\n",
    "confident_pseudolabels_df = pseudolabels_df[pseudolabels_df.pseudolabels_binary != -1]\n",
    "confident_pseudolabels_df_idx = confident_pseudolabels_df.index # used to filter out the possible drug combinations df\n",
    "\n",
    "confident_cl_drug_combinations_df = possible_cl_drug_combinations_df[possible_cl_drug_combinations_df.index.isin(confident_pseudolabels_df_idx)].copy()\n",
    "confident_cl_drug_combinations_df[\"recist\"] = list(confident_pseudolabels_df[\"pseudolabels_binary\"])\n",
    "print(\"Number of confident cl drug combinations with pseudolabels: \")\n",
    "print(confident_cl_drug_combinations_df.shape)\n",
    "print(\"Pseudo label distribution after majority vote:\")\n",
    "print(confident_cl_drug_combinations_df.recist.value_counts())\n",
    "\n",
    "# combine confident CL samples with pseudolabels, with TCGA train data\n",
    "combined_dataset_df = pd.concat([confident_cl_drug_combinations_df, train_target_data_merged[confident_cl_drug_combinations_df.columns]], axis=0)\n",
    "combined_dataset = CustomCombinedDataSetLabelled(combined_dataset_df, cl_augmented_df, train_target_inputs_vae, drug_fp)\n",
    "combined_dataloader = DataLoader(combined_dataset, batch_size=model_config[\"drp_batch_size\"], shuffle=True, worker_init_fn = seed_worker, generator = g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14069a7d-6388-4cbe-862e-5a4182d47ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.drug_embedder = nn.Sequential(nn.Linear(2048, 256), nn.ReLU(), nn.Linear(256, 64))\n",
    "        self.recist_predictor = nn.Sequential(nn.Linear(64 * 2, 16), nn.ReLU(), nn.Linear(16, 1))\n",
    "\n",
    "    def forward(self, patient_inp, patient_drug):\n",
    "        # patient_inp is 64 dim, drugs are 2048 dim\n",
    "        patient_drug_emb = self.drug_embedder(patient_drug)\n",
    "        patient_cat = torch.cat((patient_inp, patient_drug_emb), axis = 1)\n",
    "\n",
    "        # recist prediction\n",
    "        recist_pred = self.recist_predictor(patient_cat)\n",
    "\n",
    "        return recist_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d18f9a3-77cb-4495-ab80-1e743cb6d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_drp_model(model, patient_val_dataloader):\n",
    "    model.eval()\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    for idx, batch in enumerate(patient_val_dataloader):\n",
    "        with torch.no_grad():\n",
    "            patient_inp = batch[0].to(device)\n",
    "            patient_drug = batch[1].to(device)\n",
    "            label = batch[2].to(device)\n",
    "            y_preds.append(nn.Sigmoid()(model(patient_inp, patient_drug)).view(-1, 1))\n",
    "            y_trues.append(label.view(-1, 1))\n",
    "    return torch.cat(y_preds), torch.cat(y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23771145-ac47-40da-ba0a-7483119d585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_drp_model(model, train_dataloader, patient_val_dataloader, num_epochs=100, lr=1e-3):\n",
    "    \"\"\"\n",
    "    To train vanilla baseline model\n",
    "    \"\"\"\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    # training \n",
    "    val_corrs = []\n",
    "    count = 0\n",
    "    for i in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        if i > 10 and i % 10 == 0:\n",
    "            lr = lr/10\n",
    "            optim = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            optim.zero_grad()\n",
    "            patient_inp = batch[0].to(device)\n",
    "            patient_drug = batch[1].to(device)\n",
    "            label = batch[2].to(device)\n",
    "            y_pred = model(patient_inp, patient_drug).view(-1, 1)\n",
    "            loss = criterion(y_pred, label.view(-1, 1).to(device, dtype=torch.float32))\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        y_test_pred, test_y = inference_drp_model(model, patient_val_dataloader)\n",
    "        patient_corr = pearsonr(test_y.detach().cpu().numpy().reshape(-1), y_test_pred.detach().cpu().numpy().reshape(-1)).statistic + 1 # range in [0, 2]\n",
    "\n",
    "        val_corrs.append(patient_corr)\n",
    "        print(f\"Epoch {i}: Training loss: {np.mean(train_losses)} |  Validation correlation: {patient_corr}\")\n",
    "\n",
    "        # wandb.log({\n",
    "        #     f\"{model.model_name}_train_loss\": loss.detach().item(),\n",
    "        #     f\"validation_score\": patient_corr\n",
    "        # })\n",
    "        # convergence based on val score\n",
    "        if len(val_corrs) == 1: # first epoch\n",
    "            best_val_score = patient_corr\n",
    "\n",
    "        # save model\n",
    "        if model_config[\"model_save_criteria\"] in [\"val_AUROC\", \"val_AUPRC\", \"val_corr\"]: # maximise values\n",
    "            if patient_corr >= best_val_score:\n",
    "                best_val_score = patient_corr\n",
    "                # save model\n",
    "                print(\"Best model\")\n",
    "                torch.save(model.state_dict(), f\"{folder_config['model_checkpoint_folder']}/{model.model_name}_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.pth\")\n",
    "                count = 0 # reset count\n",
    "            else:\n",
    "                count += 1 # declining performance on validation data\n",
    "        else:\n",
    "            print(\"Unsupported metric for optimising\")\n",
    "            return\n",
    "        \n",
    "        if count >= 3:\n",
    "            print(\"Converged\")\n",
    "            break\n",
    "\n",
    "        # # convergence checking based on validation correlation\n",
    "        # if len(val_corrs) > 2:\n",
    "        #     if val_corrs[-1] < val_corrs[-2]: # maximise correlation\n",
    "        #         count += 1\n",
    "        #     else:\n",
    "        #         print(\"Best model\")\n",
    "        #         torch.save(model.state_dict(), f\"{folder_config['model_checkpoint_folder']}/{model.model_name}_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.pth\")\n",
    "        #         count = 0\n",
    "        # if len(val_corrs) == 1:\n",
    "        #     torch.save(model.state_dict(), f\"{folder_config['model_checkpoint_folder']}/{model.model_name}_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.pth\")\n",
    "        # if count > 3:\n",
    "        #     print(\"Converged\")\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "560e7b7f-4522-4201-9f22-2504cb7effc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_val_vae_dataset = CustomCombinedDataSetLabelled(val_target_data_merged, cl_augmented_df, val_target_inputs_vae, drug_fp)\n",
    "target_dataloader_val_vae = DataLoader(target_val_vae_dataset, batch_size=model_config[\"drp_batch_size\"], shuffle=True, worker_init_fn = seed_worker, generator = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9f5d853-f8a3-4435-988e-3eb5ffb83b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_val_vae_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36996f73-ddd9-4830-a6d8-7412e6f7625f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training loss: 0.7161241471767426 |  Validation correlation: 1.072128088636832\n",
      "Best model\n",
      "Epoch 1: Training loss: 0.7111875414848328 |  Validation correlation: 1.0741226126036283\n",
      "Best model\n",
      "Epoch 2: Training loss: 0.7036757469177246 |  Validation correlation: 1.0757869271678246\n",
      "Best model\n",
      "Epoch 3: Training loss: 0.6969688236713409 |  Validation correlation: 1.07758105547259\n",
      "Best model\n",
      "Epoch 4: Training loss: 0.7043079733848572 |  Validation correlation: 1.0794982798161044\n",
      "Best model\n",
      "Epoch 5: Training loss: 0.7013855874538422 |  Validation correlation: 1.0815653390589017\n",
      "Best model\n",
      "Epoch 6: Training loss: 0.701205849647522 |  Validation correlation: 1.0837114790962294\n",
      "Best model\n",
      "Epoch 7: Training loss: 0.6921909153461456 |  Validation correlation: 1.086042538449975\n",
      "Best model\n",
      "Epoch 8: Training loss: 0.6884322762489319 |  Validation correlation: 1.0886278837672223\n",
      "Best model\n",
      "Epoch 9: Training loss: 0.6853307783603668 |  Validation correlation: 1.0915027204495165\n",
      "Best model\n",
      "Epoch 10: Training loss: 0.6816396415233612 |  Validation correlation: 1.0946526853402554\n",
      "Best model\n",
      "Epoch 11: Training loss: 0.6781657040119171 |  Validation correlation: 1.098258868889069\n",
      "Best model\n",
      "Epoch 12: Training loss: 0.6773830950260162 |  Validation correlation: 1.1021571665372374\n",
      "Best model\n",
      "Epoch 13: Training loss: 0.6702286005020142 |  Validation correlation: 1.1065015692554847\n",
      "Best model\n",
      "Epoch 14: Training loss: 0.664147287607193 |  Validation correlation: 1.111536289533963\n",
      "Best model\n",
      "Epoch 15: Training loss: 0.6546449363231659 |  Validation correlation: 1.1172528924488863\n",
      "Best model\n",
      "Epoch 16: Training loss: 0.6622347235679626 |  Validation correlation: 1.1232229454341152\n",
      "Best model\n",
      "Epoch 17: Training loss: 0.6481068432331085 |  Validation correlation: 1.1294442224990329\n",
      "Best model\n",
      "Epoch 18: Training loss: 0.6504619717597961 |  Validation correlation: 1.1362824314893876\n",
      "Best model\n",
      "Epoch 19: Training loss: 0.6431620121002197 |  Validation correlation: 1.143539537501506\n",
      "Best model\n",
      "Epoch 20: Training loss: 0.6320724785327911 |  Validation correlation: 1.1442215497357169\n",
      "Best model\n",
      "Epoch 21: Training loss: 0.631646990776062 |  Validation correlation: 1.1448924616562495\n",
      "Best model\n",
      "Epoch 22: Training loss: 0.6388790607452393 |  Validation correlation: 1.1455681784574057\n",
      "Best model\n",
      "Epoch 23: Training loss: 0.6296646893024445 |  Validation correlation: 1.1462460313695046\n",
      "Best model\n",
      "Epoch 24: Training loss: 0.6291540563106537 |  Validation correlation: 1.1469213712595816\n",
      "Best model\n",
      "Epoch 25: Training loss: 0.6283880472183228 |  Validation correlation: 1.1476015994514117\n",
      "Best model\n",
      "Epoch 26: Training loss: 0.6378976702690125 |  Validation correlation: 1.1482870844101192\n",
      "Best model\n",
      "Epoch 27: Training loss: 0.623189389705658 |  Validation correlation: 1.1489757830003215\n",
      "Best model\n",
      "Epoch 28: Training loss: 0.6262741982936859 |  Validation correlation: 1.1496695270665487\n",
      "Best model\n",
      "Epoch 29: Training loss: 0.6350661814212799 |  Validation correlation: 1.1503658750710681\n",
      "Best model\n",
      "Epoch 30: Training loss: 0.6294078528881073 |  Validation correlation: 1.150435015963477\n",
      "Best model\n",
      "Epoch 31: Training loss: 0.6268834173679352 |  Validation correlation: 1.150502879475459\n",
      "Best model\n",
      "Epoch 32: Training loss: 0.6306512653827667 |  Validation correlation: 1.1505699259159725\n",
      "Best model\n",
      "Epoch 33: Training loss: 0.6298015713691711 |  Validation correlation: 1.150637425579619\n",
      "Best model\n",
      "Epoch 34: Training loss: 0.6343531906604767 |  Validation correlation: 1.1507065678413444\n",
      "Best model\n",
      "Epoch 35: Training loss: 0.6271352767944336 |  Validation correlation: 1.1507761548200304\n",
      "Best model\n",
      "Epoch 36: Training loss: 0.6269016265869141 |  Validation correlation: 1.1508462273850393\n",
      "Best model\n",
      "Epoch 37: Training loss: 0.628965824842453 |  Validation correlation: 1.1509164300317345\n",
      "Best model\n",
      "Epoch 38: Training loss: 0.6274067163467407 |  Validation correlation: 1.1509863673474305\n",
      "Best model\n",
      "Epoch 39: Training loss: 0.6301372647285461 |  Validation correlation: 1.151057700695821\n",
      "Best model\n",
      "Epoch 40: Training loss: 0.6254511475563049 |  Validation correlation: 1.1510645392917498\n",
      "Best model\n",
      "Epoch 41: Training loss: 0.6302202641963959 |  Validation correlation: 1.1510717699435078\n",
      "Best model\n",
      "Epoch 42: Training loss: 0.6232537627220154 |  Validation correlation: 1.1510790649586906\n",
      "Best model\n",
      "Epoch 43: Training loss: 0.6267857849597931 |  Validation correlation: 1.1510862317160202\n",
      "Best model\n",
      "Epoch 44: Training loss: 0.6246756017208099 |  Validation correlation: 1.1510932487410117\n",
      "Best model\n",
      "Epoch 45: Training loss: 0.6212652027606964 |  Validation correlation: 1.1511003053777287\n",
      "Best model\n",
      "Epoch 46: Training loss: 0.6294825375080109 |  Validation correlation: 1.1511074549209266\n",
      "Best model\n",
      "Epoch 47: Training loss: 0.6290881633758545 |  Validation correlation: 1.1511144276016638\n",
      "Best model\n",
      "Epoch 48: Training loss: 0.6316966116428375 |  Validation correlation: 1.1511213322052685\n",
      "Best model\n",
      "Epoch 49: Training loss: 0.6304222345352173 |  Validation correlation: 1.1511283342020806\n",
      "Best model\n",
      "Epoch 50: Training loss: 0.6256529092788696 |  Validation correlation: 1.1511290507151113\n",
      "Best model\n",
      "Epoch 51: Training loss: 0.6285355985164642 |  Validation correlation: 1.1511297230367605\n",
      "Best model\n",
      "Epoch 52: Training loss: 0.6290182769298553 |  Validation correlation: 1.1511304131288036\n",
      "Best model\n",
      "Epoch 53: Training loss: 0.6277841031551361 |  Validation correlation: 1.1511311060856158\n",
      "Best model\n",
      "Epoch 54: Training loss: 0.6267824172973633 |  Validation correlation: 1.1511317783510482\n",
      "Best model\n",
      "Epoch 55: Training loss: 0.6299785077571869 |  Validation correlation: 1.1511325095542724\n",
      "Best model\n",
      "Epoch 56: Training loss: 0.6314134895801544 |  Validation correlation: 1.1511332317389051\n",
      "Best model\n",
      "Epoch 57: Training loss: 0.627584844827652 |  Validation correlation: 1.1511339112677204\n",
      "Best model\n",
      "Epoch 58: Training loss: 0.6305408477783203 |  Validation correlation: 1.1511345553276824\n",
      "Best model\n",
      "Epoch 59: Training loss: 0.6220267117023468 |  Validation correlation: 1.151135443860238\n",
      "Best model\n",
      "Epoch 60: Training loss: 0.6257566511631012 |  Validation correlation: 1.1511354948662924\n",
      "Best model\n",
      "Epoch 61: Training loss: 0.6365498006343842 |  Validation correlation: 1.1511355369368186\n",
      "Best model\n",
      "Epoch 62: Training loss: 0.6331383287906647 |  Validation correlation: 1.1511355567238353\n",
      "Best model\n",
      "Epoch 63: Training loss: 0.6270950436592102 |  Validation correlation: 1.1511355911072725\n",
      "Best model\n",
      "Epoch 64: Training loss: 0.6298038065433502 |  Validation correlation: 1.1511357076352393\n",
      "Best model\n",
      "Epoch 65: Training loss: 0.6338925957679749 |  Validation correlation: 1.1511357422774582\n",
      "Best model\n",
      "Epoch 66: Training loss: 0.632663756608963 |  Validation correlation: 1.1511358309304063\n",
      "Best model\n",
      "Epoch 67: Training loss: 0.6304925084114075 |  Validation correlation: 1.1511358478543445\n",
      "Best model\n",
      "Epoch 68: Training loss: 0.6290059089660645 |  Validation correlation: 1.1511359338206673\n",
      "Best model\n",
      "Epoch 69: Training loss: 0.6263685524463654 |  Validation correlation: 1.1511359684331994\n",
      "Best model\n",
      "Epoch 70: Training loss: 0.6255438327789307 |  Validation correlation: 1.1511359588282428\n",
      "Epoch 71: Training loss: 0.630938857793808 |  Validation correlation: 1.1511359532148728\n",
      "Epoch 72: Training loss: 0.6287305057048798 |  Validation correlation: 1.1511359699215065\n",
      "Best model\n",
      "Epoch 73: Training loss: 0.6270351111888885 |  Validation correlation: 1.1511359699215065\n",
      "Best model\n",
      "Epoch 74: Training loss: 0.6267050802707672 |  Validation correlation: 1.1511359755348762\n",
      "Best model\n",
      "Epoch 75: Training loss: 0.6278022825717926 |  Validation correlation: 1.1511359603165499\n",
      "Epoch 76: Training loss: 0.6243064403533936 |  Validation correlation: 1.1511359620506272\n",
      "Epoch 77: Training loss: 0.6257946789264679 |  Validation correlation: 1.1511359524456708\n",
      "Converged\n"
     ]
    }
   ],
   "source": [
    "# initialise the DRP NN \n",
    "nn_drp = DRP().to(device)\n",
    "nn_drp.model_name = \"DRP_model\"\n",
    "\n",
    "# Train DRP model\n",
    "train_drp_model(nn_drp, combined_dataloader, target_dataloader_val_vae, num_epochs=model_config[\"drp_epochs\"], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ee05dd6-c2e0-4803-a920-e4274dd3a8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_drp_trained = DRP().to(device)\n",
    "nn_drp_trained.model_name = \"DRP_model\"\n",
    "nn_drp_trained.load_state_dict(torch.load(f\"{folder_config['model_checkpoint_folder']}/{nn_drp_trained.model_name}_{model_config['model_save_criteria']}_{model_config['experiment_id']}_{model_config['experiment_settings']}_fold{model_config['sample_id']}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86ee7d25-ddcb-4294-8fde-d79c355f40e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRP(\n",
       "  (drug_embedder): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (recist_predictor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_drp_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07c055fa-f86a-4e98-be48-2ee6a717c0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vae_feat0</th>\n",
       "      <th>vae_feat1</th>\n",
       "      <th>vae_feat2</th>\n",
       "      <th>vae_feat3</th>\n",
       "      <th>vae_feat4</th>\n",
       "      <th>vae_feat5</th>\n",
       "      <th>vae_feat6</th>\n",
       "      <th>vae_feat7</th>\n",
       "      <th>vae_feat8</th>\n",
       "      <th>vae_feat9</th>\n",
       "      <th>...</th>\n",
       "      <th>vae_feat54</th>\n",
       "      <th>vae_feat55</th>\n",
       "      <th>vae_feat56</th>\n",
       "      <th>vae_feat57</th>\n",
       "      <th>vae_feat58</th>\n",
       "      <th>vae_feat59</th>\n",
       "      <th>vae_feat60</th>\n",
       "      <th>vae_feat61</th>\n",
       "      <th>vae_feat62</th>\n",
       "      <th>vae_feat63</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-FD-A6TC</th>\n",
       "      <td>-0.083024</td>\n",
       "      <td>2.651996</td>\n",
       "      <td>-0.215026</td>\n",
       "      <td>0.356481</td>\n",
       "      <td>0.402417</td>\n",
       "      <td>-0.156310</td>\n",
       "      <td>-2.855434</td>\n",
       "      <td>5.070641</td>\n",
       "      <td>-2.372689</td>\n",
       "      <td>0.078386</td>\n",
       "      <td>...</td>\n",
       "      <td>2.159075</td>\n",
       "      <td>-2.426609</td>\n",
       "      <td>-3.386950</td>\n",
       "      <td>2.844647</td>\n",
       "      <td>3.154399</td>\n",
       "      <td>0.213879</td>\n",
       "      <td>-1.420694</td>\n",
       "      <td>-1.560417</td>\n",
       "      <td>-1.271526</td>\n",
       "      <td>2.942707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-S9-A6TS</th>\n",
       "      <td>-3.305202</td>\n",
       "      <td>0.039228</td>\n",
       "      <td>-1.770682</td>\n",
       "      <td>1.919258</td>\n",
       "      <td>-0.636432</td>\n",
       "      <td>2.485659</td>\n",
       "      <td>1.220185</td>\n",
       "      <td>2.638213</td>\n",
       "      <td>1.013089</td>\n",
       "      <td>-0.640299</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.791976</td>\n",
       "      <td>-0.717959</td>\n",
       "      <td>3.120096</td>\n",
       "      <td>3.173429</td>\n",
       "      <td>1.921328</td>\n",
       "      <td>-2.729114</td>\n",
       "      <td>0.734436</td>\n",
       "      <td>-3.837815</td>\n",
       "      <td>-4.825634</td>\n",
       "      <td>-1.474993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-VR-A8EQ</th>\n",
       "      <td>-0.980027</td>\n",
       "      <td>-2.169616</td>\n",
       "      <td>3.498873</td>\n",
       "      <td>0.194043</td>\n",
       "      <td>1.045298</td>\n",
       "      <td>-1.142655</td>\n",
       "      <td>0.566293</td>\n",
       "      <td>-4.326458</td>\n",
       "      <td>-1.245374</td>\n",
       "      <td>0.452617</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.083393</td>\n",
       "      <td>-5.880949</td>\n",
       "      <td>-3.342791</td>\n",
       "      <td>-0.498273</td>\n",
       "      <td>-3.281126</td>\n",
       "      <td>-2.108139</td>\n",
       "      <td>1.544803</td>\n",
       "      <td>3.116042</td>\n",
       "      <td>-0.872499</td>\n",
       "      <td>1.004210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_DS_bkm_034_T</th>\n",
       "      <td>-2.056072</td>\n",
       "      <td>-2.361818</td>\n",
       "      <td>1.201535</td>\n",
       "      <td>0.967723</td>\n",
       "      <td>2.763317</td>\n",
       "      <td>2.923008</td>\n",
       "      <td>0.688694</td>\n",
       "      <td>-0.444595</td>\n",
       "      <td>3.525197</td>\n",
       "      <td>-4.204098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768535</td>\n",
       "      <td>-0.299287</td>\n",
       "      <td>-1.511363</td>\n",
       "      <td>1.155748</td>\n",
       "      <td>-1.807253</td>\n",
       "      <td>-1.010847</td>\n",
       "      <td>0.375529</td>\n",
       "      <td>-0.615306</td>\n",
       "      <td>-1.983701</td>\n",
       "      <td>3.737444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-YU-A90Q</th>\n",
       "      <td>-1.874006</td>\n",
       "      <td>0.636351</td>\n",
       "      <td>0.897583</td>\n",
       "      <td>0.781874</td>\n",
       "      <td>0.998482</td>\n",
       "      <td>-2.220595</td>\n",
       "      <td>-0.187569</td>\n",
       "      <td>2.524674</td>\n",
       "      <td>-4.886362</td>\n",
       "      <td>-0.935126</td>\n",
       "      <td>...</td>\n",
       "      <td>4.744148</td>\n",
       "      <td>0.398222</td>\n",
       "      <td>1.355325</td>\n",
       "      <td>-3.137977</td>\n",
       "      <td>3.304672</td>\n",
       "      <td>2.509691</td>\n",
       "      <td>-0.574217</td>\n",
       "      <td>2.219782</td>\n",
       "      <td>0.722304</td>\n",
       "      <td>-1.029607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_DS_bkm_013_T</th>\n",
       "      <td>-3.130776</td>\n",
       "      <td>-1.876270</td>\n",
       "      <td>0.810816</td>\n",
       "      <td>1.423917</td>\n",
       "      <td>-1.094425</td>\n",
       "      <td>-1.394773</td>\n",
       "      <td>1.142573</td>\n",
       "      <td>2.746184</td>\n",
       "      <td>-0.084692</td>\n",
       "      <td>-1.348653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>1.408558</td>\n",
       "      <td>-4.212885</td>\n",
       "      <td>2.847703</td>\n",
       "      <td>-1.229921</td>\n",
       "      <td>2.611904</td>\n",
       "      <td>2.031250</td>\n",
       "      <td>1.327821</td>\n",
       "      <td>1.418653</td>\n",
       "      <td>-2.779293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-GN-A8LK</th>\n",
       "      <td>-1.369072</td>\n",
       "      <td>2.072245</td>\n",
       "      <td>2.180329</td>\n",
       "      <td>0.378629</td>\n",
       "      <td>2.378597</td>\n",
       "      <td>-0.187760</td>\n",
       "      <td>1.556226</td>\n",
       "      <td>3.800233</td>\n",
       "      <td>2.297842</td>\n",
       "      <td>3.117959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.641193</td>\n",
       "      <td>6.820119</td>\n",
       "      <td>0.346007</td>\n",
       "      <td>-2.536650</td>\n",
       "      <td>2.554804</td>\n",
       "      <td>1.666319</td>\n",
       "      <td>-0.397089</td>\n",
       "      <td>-3.832259</td>\n",
       "      <td>-2.715326</td>\n",
       "      <td>3.149523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-VS-A8EJ</th>\n",
       "      <td>-4.448752</td>\n",
       "      <td>-1.092051</td>\n",
       "      <td>-1.532695</td>\n",
       "      <td>1.490624</td>\n",
       "      <td>-0.640412</td>\n",
       "      <td>3.712206</td>\n",
       "      <td>-0.119618</td>\n",
       "      <td>0.707582</td>\n",
       "      <td>1.351033</td>\n",
       "      <td>-3.249547</td>\n",
       "      <td>...</td>\n",
       "      <td>2.887955</td>\n",
       "      <td>0.835313</td>\n",
       "      <td>0.325788</td>\n",
       "      <td>1.198399</td>\n",
       "      <td>0.160109</td>\n",
       "      <td>0.749244</td>\n",
       "      <td>2.131243</td>\n",
       "      <td>0.391114</td>\n",
       "      <td>0.239035</td>\n",
       "      <td>-2.379443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-0021780-T01-IM6</th>\n",
       "      <td>1.222566</td>\n",
       "      <td>-1.619695</td>\n",
       "      <td>2.668091</td>\n",
       "      <td>2.122313</td>\n",
       "      <td>-0.211219</td>\n",
       "      <td>-2.238830</td>\n",
       "      <td>0.720097</td>\n",
       "      <td>0.237157</td>\n",
       "      <td>-6.984531</td>\n",
       "      <td>3.404870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072909</td>\n",
       "      <td>2.687999</td>\n",
       "      <td>0.892123</td>\n",
       "      <td>-5.304945</td>\n",
       "      <td>2.225888</td>\n",
       "      <td>-1.757111</td>\n",
       "      <td>-1.223737</td>\n",
       "      <td>1.793314</td>\n",
       "      <td>1.977360</td>\n",
       "      <td>-0.458780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-VS-A8EK</th>\n",
       "      <td>-3.227787</td>\n",
       "      <td>-2.595973</td>\n",
       "      <td>-0.022684</td>\n",
       "      <td>-1.163908</td>\n",
       "      <td>-0.855451</td>\n",
       "      <td>-0.512069</td>\n",
       "      <td>-0.045129</td>\n",
       "      <td>-1.104000</td>\n",
       "      <td>-4.111845</td>\n",
       "      <td>0.464358</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.589906</td>\n",
       "      <td>0.836214</td>\n",
       "      <td>-1.371708</td>\n",
       "      <td>2.915257</td>\n",
       "      <td>1.129524</td>\n",
       "      <td>-0.354992</td>\n",
       "      <td>-2.553972</td>\n",
       "      <td>1.907657</td>\n",
       "      <td>-2.245686</td>\n",
       "      <td>-1.740373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   vae_feat0  vae_feat1  vae_feat2  vae_feat3  vae_feat4  \\\n",
       "sample_id                                                                  \n",
       "TCGA-FD-A6TC       -0.083024   2.651996  -0.215026   0.356481   0.402417   \n",
       "TCGA-S9-A6TS       -3.305202   0.039228  -1.770682   1.919258  -0.636432   \n",
       "TCGA-VR-A8EQ       -0.980027  -2.169616   3.498873   0.194043   1.045298   \n",
       "s_DS_bkm_034_T     -2.056072  -2.361818   1.201535   0.967723   2.763317   \n",
       "TCGA-YU-A90Q       -1.874006   0.636351   0.897583   0.781874   0.998482   \n",
       "...                      ...        ...        ...        ...        ...   \n",
       "s_DS_bkm_013_T     -3.130776  -1.876270   0.810816   1.423917  -1.094425   \n",
       "TCGA-GN-A8LK       -1.369072   2.072245   2.180329   0.378629   2.378597   \n",
       "TCGA-VS-A8EJ       -4.448752  -1.092051  -1.532695   1.490624  -0.640412   \n",
       "P-0021780-T01-IM6   1.222566  -1.619695   2.668091   2.122313  -0.211219   \n",
       "TCGA-VS-A8EK       -3.227787  -2.595973  -0.022684  -1.163908  -0.855451   \n",
       "\n",
       "                   vae_feat5  vae_feat6  vae_feat7  vae_feat8  vae_feat9  ...  \\\n",
       "sample_id                                                                 ...   \n",
       "TCGA-FD-A6TC       -0.156310  -2.855434   5.070641  -2.372689   0.078386  ...   \n",
       "TCGA-S9-A6TS        2.485659   1.220185   2.638213   1.013089  -0.640299  ...   \n",
       "TCGA-VR-A8EQ       -1.142655   0.566293  -4.326458  -1.245374   0.452617  ...   \n",
       "s_DS_bkm_034_T      2.923008   0.688694  -0.444595   3.525197  -4.204098  ...   \n",
       "TCGA-YU-A90Q       -2.220595  -0.187569   2.524674  -4.886362  -0.935126  ...   \n",
       "...                      ...        ...        ...        ...        ...  ...   \n",
       "s_DS_bkm_013_T     -1.394773   1.142573   2.746184  -0.084692  -1.348653  ...   \n",
       "TCGA-GN-A8LK       -0.187760   1.556226   3.800233   2.297842   3.117959  ...   \n",
       "TCGA-VS-A8EJ        3.712206  -0.119618   0.707582   1.351033  -3.249547  ...   \n",
       "P-0021780-T01-IM6  -2.238830   0.720097   0.237157  -6.984531   3.404870  ...   \n",
       "TCGA-VS-A8EK       -0.512069  -0.045129  -1.104000  -4.111845   0.464358  ...   \n",
       "\n",
       "                   vae_feat54  vae_feat55  vae_feat56  vae_feat57  vae_feat58  \\\n",
       "sample_id                                                                       \n",
       "TCGA-FD-A6TC         2.159075   -2.426609   -3.386950    2.844647    3.154399   \n",
       "TCGA-S9-A6TS        -1.791976   -0.717959    3.120096    3.173429    1.921328   \n",
       "TCGA-VR-A8EQ        -1.083393   -5.880949   -3.342791   -0.498273   -3.281126   \n",
       "s_DS_bkm_034_T       0.768535   -0.299287   -1.511363    1.155748   -1.807253   \n",
       "TCGA-YU-A90Q         4.744148    0.398222    1.355325   -3.137977    3.304672   \n",
       "...                       ...         ...         ...         ...         ...   \n",
       "s_DS_bkm_013_T       0.084700    1.408558   -4.212885    2.847703   -1.229921   \n",
       "TCGA-GN-A8LK        -0.641193    6.820119    0.346007   -2.536650    2.554804   \n",
       "TCGA-VS-A8EJ         2.887955    0.835313    0.325788    1.198399    0.160109   \n",
       "P-0021780-T01-IM6   -0.072909    2.687999    0.892123   -5.304945    2.225888   \n",
       "TCGA-VS-A8EK        -2.589906    0.836214   -1.371708    2.915257    1.129524   \n",
       "\n",
       "                   vae_feat59  vae_feat60  vae_feat61  vae_feat62  vae_feat63  \n",
       "sample_id                                                                      \n",
       "TCGA-FD-A6TC         0.213879   -1.420694   -1.560417   -1.271526    2.942707  \n",
       "TCGA-S9-A6TS        -2.729114    0.734436   -3.837815   -4.825634   -1.474993  \n",
       "TCGA-VR-A8EQ        -2.108139    1.544803    3.116042   -0.872499    1.004210  \n",
       "s_DS_bkm_034_T      -1.010847    0.375529   -0.615306   -1.983701    3.737444  \n",
       "TCGA-YU-A90Q         2.509691   -0.574217    2.219782    0.722304   -1.029607  \n",
       "...                       ...         ...         ...         ...         ...  \n",
       "s_DS_bkm_013_T       2.611904    2.031250    1.327821    1.418653   -2.779293  \n",
       "TCGA-GN-A8LK         1.666319   -0.397089   -3.832259   -2.715326    3.149523  \n",
       "TCGA-VS-A8EJ         0.749244    2.131243    0.391114    0.239035   -2.379443  \n",
       "P-0021780-T01-IM6   -1.757111   -1.223737    1.793314    1.977360   -0.458780  \n",
       "TCGA-VS-A8EK        -0.354992   -2.553972    1.907657   -2.245686   -1.740373  \n",
       "\n",
       "[488 rows x 64 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_inputs_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52b8761a-d220-49fc-9248-c02e6b747214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target test\n",
    "target_test_vae_dataset = CustomCombinedDataSetLabelled(test_target_data_merged, cl_augmented_df, test_target_inputs_vae, drug_fp)\n",
    "target_dataloader_test_vae = DataLoader(target_test_vae_dataset, batch_size=model_config[\"drp_batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a1e8185-b3b8-4c54-b7dc-eebe8588c7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_test_vae_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ded16e37-2956-4af4-b552-491b84598071",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred, test_y = inference_drp_model(nn_drp_trained, target_dataloader_test_vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b9ae7e6-920a-4221-ab48-cf612c0257ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame()\n",
    "res_df[\"y_pred\"] = y_test_pred.cpu().detach().numpy().reshape(-1)\n",
    "res_df[\"y_true\"] = test_y.cpu().detach().numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1db10d4e-0905-4128-8d00-daea2d95f20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.257566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.352719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.394542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.439908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.344860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.324266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.285182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.358875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.373649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_pred  y_true\n",
       "0    0.259232       0\n",
       "1    0.257566       1\n",
       "2    0.352719       0\n",
       "3    0.394542       0\n",
       "4    0.439908       0\n",
       "..        ...     ...\n",
       "109  0.344860       1\n",
       "110  0.324266       0\n",
       "111  0.285182       0\n",
       "112  0.358875       0\n",
       "113  0.373649       0\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47d48405-e030-4861-a6e3-f7a343d899a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17d22d8d-3c21-4fef-8886-67c71a7ba134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5615530303030303"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(res_df[\"y_true\"], res_df[\"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1f4bab5-9f29-4c64-8661-b55ca8c1e728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4622265964082507"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(res_df[\"y_true\"], res_df[\"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f30123e-4b76-4a28-a4fb-755ebf5e841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv(f\"{folder_config['model_checkpoint_folder']}/prediction_patients_val_corr_2A_ALL_fold{fold}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e93266-71bb-497c-98bd-4167d72c62f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:systematic_assessment] *",
   "language": "python",
   "name": "conda-env-systematic_assessment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
